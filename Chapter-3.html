<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Reliability in poverty measurement | Multidimensional poverty measurement: A statistical approach with applications</title>
  <meta name="description" content="Chapter 3 Reliability in poverty measurement | Multidimensional poverty measurement: A statistical approach with applications" />
  <meta name="generator" content="bookdown 0.10 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Reliability in poverty measurement | Multidimensional poverty measurement: A statistical approach with applications" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Reliability in poverty measurement | Multidimensional poverty measurement: A statistical approach with applications" />
  
  
  

<meta name="author" content="Héctor Nájera with help from other academics collaborating in this project (please cite this draft)" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="Chapter-2.html">
<link rel="next" href="Chapter-4.html">
<script src="assets/jquery-2.2.3/jquery.min.js"></script>
<link href="assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="Chapter-1.html"><a href="Chapter-1.html"><i class="fa fa-check"></i><b>1</b> Poverty and measurement theory principles</a><ul>
<li class="chapter" data-level="1.1" data-path="Chapter-1.html"><a href="Chapter-1.html#the-concept-of-poverty"><i class="fa fa-check"></i><b>1.1</b> The Concept of Poverty</a></li>
<li class="chapter" data-level="1.2" data-path="Chapter-1.html"><a href="Chapter-1.html#Chapter-1-dimensions"><i class="fa fa-check"></i><b>1.2</b> Theoretical dimensions of poverty</a></li>
<li class="chapter" data-level="1.3" data-path="Chapter-1.html"><a href="Chapter-1.html#the-measurement-of-poverty-and-its-challenges"><i class="fa fa-check"></i><b>1.3</b> The measurement of poverty and its challenges</a><ul>
<li class="chapter" data-level="1.3.1" data-path="Chapter-1.html"><a href="Chapter-1.html#challenges-in-selection-of-dimensions-contents-cut-offs-and-weights"><i class="fa fa-check"></i><b>1.3.1</b> Challenges in selection of dimensions, contents, cut offs and weights</a></li>
<li class="chapter" data-level="1.3.2" data-path="Chapter-1.html"><a href="Chapter-1.html#challenges-in-aggregation-and-identification-of-the-poor"><i class="fa fa-check"></i><b>1.3.2</b> Challenges in aggregation and identification of the poor</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="Chapter-1.html"><a href="Chapter-1.html#the-poor-and-the-not-poor-the-poverty-line"><i class="fa fa-check"></i><b>1.4</b> The poor and the not poor: The poverty line</a></li>
<li class="chapter" data-level="1.5" data-path="Chapter-1.html"><a href="Chapter-1.html#a-brief-on-multidimensional-poverty-measurement"><i class="fa fa-check"></i><b>1.5</b> A brief on multidimensional poverty measurement</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chapter-2.html"><a href="Chapter-2.html"><i class="fa fa-check"></i><b>2</b> Poverty and measurement theory: A statistical framework</a><ul>
<li class="chapter" data-level="2.1" data-path="Chapter-2.html"><a href="Chapter-2.html#workflow-in-poverty-measurement-a-falsifiable-framework"><i class="fa fa-check"></i><b>2.1</b> Workflow in poverty measurement: A falsifiable framework</a></li>
<li class="chapter" data-level="2.2" data-path="Chapter-2.html"><a href="Chapter-2.html#samplingspace"><i class="fa fa-check"></i><b>2.2</b> Identification of the sampling space</a></li>
<li class="chapter" data-level="2.3" data-path="Chapter-2.html"><a href="Chapter-2.html#selection-of-dimensions-and-indicators"><i class="fa fa-check"></i><b>2.3</b> Selection of dimensions and indicators</a></li>
<li class="chapter" data-level="2.4" data-path="Chapter-2.html"><a href="Chapter-2.html#aggregation-and-weighting"><i class="fa fa-check"></i><b>2.4</b> Aggregation and weighting</a><ul>
<li class="chapter" data-level="2.4.1" data-path="Chapter-2.html"><a href="Chapter-2.html#splitting-the-population-into-meaningful-groups"><i class="fa fa-check"></i><b>2.4.1</b> Splitting the population into meaningful groups</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="Chapter-2.html"><a href="Chapter-2.html#measurement-theory-as-an-statistical-framework"><i class="fa fa-check"></i><b>2.5</b> Measurement theory as an statistical framework</a></li>
<li class="chapter" data-level="2.6" data-path="Chapter-2.html"><a href="Chapter-2.html#poverty-and-error-in-measurement"><i class="fa fa-check"></i><b>2.6</b> Poverty and error in measurement</a></li>
<li class="chapter" data-level="2.7" data-path="Chapter-2.html"><a href="Chapter-2.html#measurement-model-for-poverty"><i class="fa fa-check"></i><b>2.7</b> Measurement model for poverty</a></li>
<li class="chapter" data-level="2.8" data-path="Chapter-2.html"><a href="Chapter-2.html#Chapter-2-blueprint"><i class="fa fa-check"></i><b>2.8</b> Blueprints and poverty measurement models</a></li>
<li class="chapter" data-level="2.9" data-path="Chapter-2.html"><a href="Chapter-2.html#measurement-theory-and-principles"><i class="fa fa-check"></i><b>2.9</b> Measurement theory and principles</a><ul>
<li class="chapter" data-level="2.9.1" data-path="Chapter-2.html"><a href="Chapter-2.html#origins-of-measurement-theory"><i class="fa fa-check"></i><b>2.9.1</b> Origins of measurement theory</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Chapter-3.html"><a href="Chapter-3.html"><i class="fa fa-check"></i><b>3</b> Reliability in poverty measurement</a><ul>
<li class="chapter" data-level="3.1" data-path="Chapter-3.html"><a href="Chapter-3.html#intuition-to-the-concept-of-reliability"><i class="fa fa-check"></i><b>3.1</b> Intuition to the concept of reliability</a></li>
<li class="chapter" data-level="3.2" data-path="Chapter-3.html"><a href="Chapter-3.html#reliability-theory"><i class="fa fa-check"></i><b>3.2</b> Reliability theory</a></li>
<li class="chapter" data-level="3.3" data-path="Chapter-3.html"><a href="Chapter-3.html#Chapter-3-measuresrel"><i class="fa fa-check"></i><b>3.3</b> Statistical measures of reliability</a></li>
<li class="chapter" data-level="3.4" data-path="Chapter-3.html"><a href="Chapter-3.html#itemlevelrel"><i class="fa fa-check"></i><b>3.4</b> Item-level reliability and weighting</a></li>
<li class="chapter" data-level="3.5" data-path="Chapter-3.html"><a href="Chapter-3.html#relestimation"><i class="fa fa-check"></i><b>3.5</b> Estimation of Reliability</a><ul>
<li class="chapter" data-level="3.5.1" data-path="Chapter-3.html"><a href="Chapter-3.html#overall-reliability"><i class="fa fa-check"></i><b>3.5.1</b> Overall reliability</a></li>
<li class="chapter" data-level="3.5.2" data-path="Chapter-3.html"><a href="Chapter-3.html#Chapter-3-expoverel"><i class="fa fa-check"></i><b>3.5.2</b> Exploratory (non-model based) estimation of overall reliability</a></li>
<li class="chapter" data-level="3.5.3" data-path="Chapter-3.html"><a href="Chapter-3.html#model-based-estimation-of-overall-reliability"><i class="fa fa-check"></i><b>3.5.3</b> Model-based estimation of overall reliability</a></li>
<li class="chapter" data-level="3.5.4" data-path="Chapter-3.html"><a href="Chapter-3.html#overall-reliability-and-population-orderings"><i class="fa fa-check"></i><b>3.5.4</b> Overall reliability and population orderings</a></li>
<li class="chapter" data-level="3.5.5" data-path="Chapter-3.html"><a href="Chapter-3.html#item-level-reliability"><i class="fa fa-check"></i><b>3.5.5</b> Item-level reliability</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="Chapter-3.html"><a href="Chapter-3.html#multidimensional-item-reliability-evaluation"><i class="fa fa-check"></i><b>3.6</b> Multidimensional item-reliability evaluation</a><ul>
<li class="chapter" data-level="3.6.1" data-path="Chapter-3.html"><a href="Chapter-3.html#item-reliability-and-monotonicity"><i class="fa fa-check"></i><b>3.6.1</b> Item-reliability and monotonicity</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="Chapter-3.html"><a href="Chapter-3.html#real-data-example"><i class="fa fa-check"></i><b>3.7</b> Real data example</a><ul>
<li class="chapter" data-level="3.7.1" data-path="Chapter-3.html"><a href="Chapter-3.html#overall-reliability-1"><i class="fa fa-check"></i><b>3.7.1</b> Overall reliability</a></li>
<li class="chapter" data-level="3.7.2" data-path="Chapter-3.html"><a href="Chapter-3.html#item-level-reliability-1"><i class="fa fa-check"></i><b>3.7.2</b> Item-level reliability</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Chapter-4.html"><a href="Chapter-4.html"><i class="fa fa-check"></i><b>4</b> Validity in poverty measurement</a><ul>
<li class="chapter" data-level="4.1" data-path="Chapter-4.html"><a href="Chapter-4.html#intuition-to-the-concept-of-validity"><i class="fa fa-check"></i><b>4.1</b> Intuition to the concept of validity</a></li>
<li class="chapter" data-level="4.2" data-path="Chapter-4.html"><a href="Chapter-4.html#theory-of-validity"><i class="fa fa-check"></i><b>4.2</b> Theory of validity</a></li>
<li class="chapter" data-level="4.3" data-path="Chapter-4.html"><a href="Chapter-4.html#methods-for-the-analysis-validity"><i class="fa fa-check"></i><b>4.3</b> Methods for the analysis validity</a><ul>
<li class="chapter" data-level="4.3.1" data-path="Chapter-4.html"><a href="Chapter-4.html#criterion-validity"><i class="fa fa-check"></i><b>4.3.1</b> Criterion validity</a></li>
<li class="chapter" data-level="4.3.2" data-path="Chapter-4.html"><a href="Chapter-4.html#construct-validity"><i class="fa fa-check"></i><b>4.3.2</b> Construct validity</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="Chapter-4.html"><a href="Chapter-4.html#validity-assessment"><i class="fa fa-check"></i><b>4.4</b> Validity assessment</a><ul>
<li class="chapter" data-level="4.4.1" data-path="Chapter-4.html"><a href="Chapter-4.html#criterion-validity-1"><i class="fa fa-check"></i><b>4.4.1</b> Criterion Validity</a></li>
<li class="chapter" data-level="4.4.2" data-path="Chapter-4.html"><a href="Chapter-4.html#construct-validity-1"><i class="fa fa-check"></i><b>4.4.2</b> Construct Validity</a></li>
<li class="chapter" data-level="4.4.3" data-path="Chapter-4.html"><a href="Chapter-4.html#a-joint-assessment-criterion-and-construct-validity"><i class="fa fa-check"></i><b>4.4.3</b> A joint assessment: Criterion and construct validity</a></li>
<li class="chapter" data-level="4.4.4" data-path="Chapter-4.html"><a href="Chapter-4.html#real-data-example-1"><i class="fa fa-check"></i><b>4.4.4</b> Real-data example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Chapter-5.html"><a href="Chapter-5.html"><i class="fa fa-check"></i><b>5</b> Comparability in poverty measurement</a><ul>
<li class="chapter" data-level="5.1" data-path="Chapter-5.html"><a href="Chapter-5.html#measurement-invariance"><i class="fa fa-check"></i><b>5.1</b> Measurement invariance</a></li>
<li class="chapter" data-level="5.2" data-path="Chapter-5.html"><a href="Chapter-5.html#introduction-to-key-aspects-of-measurement-invariance"><i class="fa fa-check"></i><b>5.2</b> Introduction to key aspects of measurement invariance</a></li>
<li class="chapter" data-level="5.3" data-path="Chapter-5.html"><a href="Chapter-5.html#methods-for-the-assessment-of-measurement-invariance"><i class="fa fa-check"></i><b>5.3</b> Methods for the assessment of Measurement Invariance</a><ul>
<li class="chapter" data-level="5.3.1" data-path="Chapter-5.html"><a href="Chapter-5.html#multiple-group-factor-analysis"><i class="fa fa-check"></i><b>5.3.1</b> Multiple Group Factor Analysis</a></li>
<li class="chapter" data-level="5.3.2" data-path="Chapter-5.html"><a href="Chapter-5.html#the-alignment-method"><i class="fa fa-check"></i><b>5.3.2</b> The alignment method</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="Chapter-5.html"><a href="Chapter-5.html#real-data-analysis-of-measurement-invariance"><i class="fa fa-check"></i><b>5.4</b> Real-data analysis of Measurement Invariance</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="scale-equating-and-linking.html"><a href="scale-equating-and-linking.html"><i class="fa fa-check"></i><b>6</b> Scale equating and linking</a><ul>
<li class="chapter" data-level="6.1" data-path="scale-equating-and-linking.html"><a href="scale-equating-and-linking.html#intuition-to-scale-equating"><i class="fa fa-check"></i><b>6.1</b> Intuition to scale equating</a></li>
<li class="chapter" data-level="6.2" data-path="scale-equating-and-linking.html"><a href="scale-equating-and-linking.html#theory-of-scale-equating-theoryequating"><i class="fa fa-check"></i><b>6.2</b> Theory of scale equating [#Theoryequating]</a><ul>
<li class="chapter" data-level="6.2.1" data-path="scale-equating-and-linking.html"><a href="scale-equating-and-linking.html#workflow-in-scale-equating"><i class="fa fa-check"></i><b>6.2.1</b> Workflow in scale equating</a></li>
<li class="chapter" data-level="6.2.2" data-path="scale-equating-and-linking.html"><a href="scale-equating-and-linking.html#theory-of-irt-scale-equating"><i class="fa fa-check"></i><b>6.2.2</b> Theory of IRT scale equating</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="scale-equating-and-linking.html"><a href="scale-equating-and-linking.html#data-and-designs-in-test-equating"><i class="fa fa-check"></i><b>6.3</b> Data and designs in test equating</a><ul>
<li class="chapter" data-level="6.3.1" data-path="scale-equating-and-linking.html"><a href="scale-equating-and-linking.html#single-group-design"><i class="fa fa-check"></i><b>6.3.1</b> Single group design</a></li>
<li class="chapter" data-level="6.3.2" data-path="scale-equating-and-linking.html"><a href="scale-equating-and-linking.html#equivalent-groups-design"><i class="fa fa-check"></i><b>6.3.2</b> Equivalent groups design</a></li>
<li class="chapter" data-level="6.3.3" data-path="scale-equating-and-linking.html"><a href="scale-equating-and-linking.html#non-equivalent-groups-with-anchor-test-design"><i class="fa fa-check"></i><b>6.3.3</b> Non Equivalent Groups with Anchor test Design</a></li>
<li class="chapter" data-level="6.3.4" data-path="scale-equating-and-linking.html"><a href="scale-equating-and-linking.html#non-equivalent-groups-with-covariates-design"><i class="fa fa-check"></i><b>6.3.4</b> Non Equivalent Groups with Covariates Design</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="scale-equating-and-linking.html"><a href="scale-equating-and-linking.html#example-of-irt-equating-neat-design-with-simulated-data-in-r"><i class="fa fa-check"></i><b>6.4</b> Example of IRT equating (NEAT design) with simulated data in R</a></li>
<li class="chapter" data-level="6.5" data-path="scale-equating-and-linking.html"><a href="scale-equating-and-linking.html#real-data-example-2"><i class="fa fa-check"></i><b>6.5</b> Real-data example</a><ul>
<li class="chapter" data-level="6.5.1" data-path="scale-equating-and-linking.html"><a href="scale-equating-and-linking.html#step-1-finding-the-anchors.-mi-analysis"><i class="fa fa-check"></i><b>6.5.1</b> Step 1: Finding the anchors. MI Analysis</a></li>
<li class="chapter" data-level="6.5.2" data-path="scale-equating-and-linking.html"><a href="scale-equating-and-linking.html#step-2-extract-irt-parameters-for-each-of-10-indices"><i class="fa fa-check"></i><b>6.5.2</b> Step 2: Extract IRT parameters for each of 10 indices</a></li>
<li class="chapter" data-level="6.5.3" data-path="scale-equating-and-linking.html"><a href="scale-equating-and-linking.html#step-3-estimating-the-constants-for-equating"><i class="fa fa-check"></i><b>6.5.3</b> Step 3: Estimating the constants for equating</a></li>
<li class="chapter" data-level="6.5.4" data-path="scale-equating-and-linking.html"><a href="scale-equating-and-linking.html#step-4-applying-the-constants-and-obtaning-equated-scores"><i class="fa fa-check"></i><b>6.5.4</b> Step 4: Applying the constants and obtaning equated scores</a></li>
<li class="chapter" data-level="6.5.5" data-path="scale-equating-and-linking.html"><a href="scale-equating-and-linking.html#finding-equated-poverty-lines"><i class="fa fa-check"></i><b>6.5.5</b> Finding equated poverty lines</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="identifying-the-poor-group.html"><a href="identifying-the-poor-group.html"><i class="fa fa-check"></i><b>7</b> Identifying the poor group</a><ul>
<li class="chapter" data-level="7.1" data-path="identifying-the-poor-group.html"><a href="identifying-the-poor-group.html#the-poverty-line"><i class="fa fa-check"></i><b>7.1</b> The poverty line</a></li>
<li class="chapter" data-level="7.2" data-path="identifying-the-poor-group.html"><a href="identifying-the-poor-group.html#perspectives-on-the-poverty-line-union-and-intersection-approaches"><i class="fa fa-check"></i><b>7.2</b> Perspectives on the poverty line: Union and intersection approaches</a></li>
<li class="chapter" data-level="7.3" data-path="identifying-the-poor-group.html"><a href="identifying-the-poor-group.html#the-human-rights-based-approach"><i class="fa fa-check"></i><b>7.3</b> The human rights-based approach</a></li>
<li class="chapter" data-level="7.4" data-path="identifying-the-poor-group.html"><a href="identifying-the-poor-group.html#the-ubn-weighted-approach"><i class="fa fa-check"></i><b>7.4</b> The UBN weighted approach</a></li>
<li class="chapter" data-level="7.5" data-path="identifying-the-poor-group.html"><a href="identifying-the-poor-group.html#the-partially-weighted-approach"><i class="fa fa-check"></i><b>7.5</b> The partially-weighted approach</a></li>
<li class="chapter" data-level="7.6" data-path="identifying-the-poor-group.html"><a href="identifying-the-poor-group.html#the-bristol-optimal-approach"><i class="fa fa-check"></i><b>7.6</b> The Bristol Optimal approach</a></li>
<li class="chapter" data-level="7.7" data-path="identifying-the-poor-group.html"><a href="identifying-the-poor-group.html#example-with-simulated-data"><i class="fa fa-check"></i><b>7.7</b> Example with simulated data</a></li>
<li class="chapter" data-level="7.8" data-path="identifying-the-poor-group.html"><a href="identifying-the-poor-group.html#real-data-analysis"><i class="fa fa-check"></i><b>7.8</b> Real-data analysis</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="final-thoughts.html"><a href="final-thoughts.html"><i class="fa fa-check"></i><b>8</b> Final thoughts</a><ul>
<li class="chapter" data-level="8.1" data-path="final-thoughts.html"><a href="final-thoughts.html#the-future-of-data-production-in-multidimensional-poverty-measurement"><i class="fa fa-check"></i><b>8.1</b> The future of data production in multidimensional poverty measurement</a></li>
<li class="chapter" data-level="8.2" data-path="final-thoughts.html"><a href="final-thoughts.html#advanced-topics-in-multidimensional-poverty-measurement"><i class="fa fa-check"></i><b>8.2</b> Advanced topics in multidimensional poverty measurement</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>9</b> References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Multidimensional poverty measurement: A statistical approach with applications</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="Chapter-3" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Reliability in poverty measurement</h1>
<p><strong>Abstract</strong></p>
<p>This chapter introduces the theory and concept of reliability. An intuitive explanation is provided at the beginning of the chapter to underline the implications of reliability for measurement. Then, a formal introduction to the theory of reliability is provided. Reliability can be estimated using different approaches, the chapter discusses its limitations. The second main section of the chapter illustrates how reliability works and how can it be estimated using <strong>R</strong> and <strong>Mplus</strong> by using simulated data. Then a real-data example is used to show some of the typical problems involved in the examination of reliability.</p>
<div id="intuition-to-the-concept-of-reliability" class="section level2">
<h2><span class="header-section-number">3.1</span> Intuition to the concept of reliability</h2>
<p>In what sense the concept of reliability relates to the idea of having a measure we can trust? Poverty analysts and policymakers require indices they believe in to focus on more important issues like developing and studying poverty eradication strategies. There is nothing worse in measurement that a scale that causes disbelief in that the debate concentrates upon how bad a measure is and not upon how good or bad a policy is. `Trust’ is built upon consistent and meaningful estimates. For example, imagine a case in which we could conduct two surveys to the same population. Ideally, we expect to find that the response patterns remain unchanged from <span class="math inline">\(t_1\)</span> to <span class="math inline">\(t_2\)</span>. This is telling us that our index is stable across samples. A noisy index, in contrast, would lead to unstable responses and it is impossible to distinguish a signal (the thing we are interested in) from noise (unnecessary and confusing variability). However, consistency is not simply having the same response patterns <em>ceteris paribus</em> across two samples. The main implication for measurement of consistency is that we will get systematic population orderings, i.e. people ranked with very low (latent) living standards should remain in the same position across different measurements<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>.</p>
<p>One useful way to think about reliability in measurement is by imagining what would happen to our population orderings when we have good and bad indicators. Imagine a case in which one of the deprivation indicators is not a good measure of poverty, like having a folding bicycle. This variable will have a low correlation with the rest of the deprivation indicators. <span class="citation">Spearman (<a href="references.html#ref-Spearman1904" role="doc-biblioref">1904</a>)</span>’s theory of reliability (or attenuation) tells us to be suspicious about such kind of behaviour. The problem is that low correlation (or even worse negative correlation) could mean that the indicator in question in not a consequence by poverty (“Lack of command of resources over time” See Chapter <a href="Chapter-1.html#Chapter-1">1</a>). The effect of bad indicators is that we will end up with two different population rankings depending on whether we include folding bicycle in our index. How different? It will depend upon how poorly correlated the indicator in question is with the rest and how good the rest of indicators is as a whole -i.e. how reliable these are-. Therefore, even with a very similar response pattern, our scale will be rather unstable to be trusted. Of course, if we know that the folding bicycle item is an unreasonable measure of poverty, we would have drop it before the empirical analysis. However, as we will see with some examples, in poverty measurement there are variables or thresholds of these variables that are quite contested.</p>
<p>Now imagine a different scenario where we have only good outcome measures of poverty and, for some reason, a good variable like lacking drinking piped water inside the house is dropped from the index (assuming this is a developing country where this measure works!). If we drop this indicator from our analysis, we would lose valuable information. Making the signal weaker is not as difficult as it might seem. Lack of good quality data or bad theories will increase the risk of missing some good indicators. Therefore, we would like that our scale is protected against the perils of real-data analysis. In other words, we would like to have a measure that is not too sensible to information losses. Reliability theory aims at this kind of scenario. That, indeed, put us in a position of producing measures we can trust. High reliability is a property that, for instance, protects an index against certain information losses, i.e. the higher the reliability, the lower the effect of missing variables. Yet, missing indicators could be damaging for policy reasons, of course.</p>
</div>
<div id="reliability-theory" class="section level2">
<h2><span class="header-section-number">3.2</span> Reliability theory</h2>
<p>Reliability is a key concept in measurement theory and can be simple defined as the homogeneity of an index <span class="citation">(Revelle &amp; Zinbarg, <a href="references.html#ref-Revelle2009" role="doc-biblioref">2009</a>)</span>. A homogeneous index is a scale whose indicators are manifestations of the same trait, which is why from <span class="citation">Spearman (<a href="references.html#ref-Spearman1904" role="doc-biblioref">1904</a>)</span>’s theory we expect them to be correlated as they are caused by the same phenomenon<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>. In the literature, several authors refer to reliability as internal consistency of an index because this a consequence of homogeneity. How this term of homogeneity relate to our intuition about reliability? In the example above having an indicator that is not a good measure of poverty means that the index is heterogeneous -i.e. there is more than more phenomenon causing deprivation- and therefore leads to inconsistent population orderings. Thus at the core of the principle of reliability lies the idea of having a series of items that would have a predictable behaviour when aggregated, i.e. if an index is reliable we should expect to have very similar population rankings across samples or small variations of the same reliable index with more or less indicators<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a>.</p>
<p>The history of the theory of reliability is inextricably connected with the birth and evolution of measurement theory. The theory of reliability can be traced back to classical test theory (CTT) but it has been under continuous development by more recent breakthroughs in latent variable modelling. Reliability is rooted in the acknowledgement that all measures have an unknown mixture of signal (the concept we are interested in measuring) and noise (undesired variability-error). For <span class="citation">Spearman (<a href="references.html#ref-Spearman1904" role="doc-biblioref">1904</a>)</span> there should be a <em>true</em> score- that is just the combination of an observed score and error (See <a href="Chapter-3.html#eq:truescore">(3.1)</a>, i.e. it should be possible to assess the extent to which the association between the true score and the observed score is <em>attenuated</em> by noise. As in classical or frequentists statistics, it is <em>true</em> in the sense of the expected score across many replications of the same experiment. This is different to thing that is <em>given</em> by nature. Being <span class="math inline">\(\theta\)</span> the true score, in CTT reliability is expressed as:</p>
<p><span class="math display" id="eq:truescore">\[\begin{equation}
\tag{3.1}
x = \theta + \varepsilon
\end{equation}\]</span></p>
<p>Equation <a href="Chapter-3.html#eq:truescore">(3.1)</a> can be put in terms of variance decomposition, i.e. a ratio of how much variability is due to signal and how much is due to noise. The variance of the observed score “x” <span class="math inline">\(\sigma^{2}_{x}\)</span> is thus equal to the variance of the true score plus the variance of the error. The discrepancy between the true score and the observed score is an estimate of reliability (we will below that there are many):</p>
<p><span class="math display" id="eq:reliability1">\[\begin{equation}
\tag{3.2}
  \rho =  \frac{\sigma^{2}_{\theta}} {\sigma^{2}_{x} + \sigma^{2}_{e}}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\rho\)</span> is the total reliability and <span class="math inline">\(\sigma^{2}_{x}\)</span> is the observed variability and <span class="math inline">\(\sigma^{2}_{e}\)</span> is the measurement error. Because this is a simple proportion, the reliability estimate will be (almost) always between 0 and 1<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>. For readers looking for the full formal treatment, we will strongly recommend William Revelle’s reliability on-line source knitr::include_url(<a href="https://personality-project.org/revelle/publications/reliability-final.pdf" class="uri">https://personality-project.org/revelle/publications/reliability-final.pdf</a>):</p>
<p>This classical definition of reliability has been translated and adopted by the modern treatment of measurement theory: the latent variable approach <span class="citation">(Kvalheim, <a href="references.html#ref-Kvalheim2012" role="doc-biblioref">2012</a>; Raykov, Dimitrov, &amp; Asparouhov, <a href="references.html#ref-Raykov2010" role="doc-biblioref">2010</a>; Rusch et al., <a href="references.html#ref-Rusch2017" role="doc-biblioref">2017</a>; Skrondal &amp; Rabe-Hesketh, <a href="references.html#ref-Skrondal2007" role="doc-biblioref">2007</a>)</span>. Yet, there are substantive commonalities and differences between these two approaches <span class="citation">(Petrillo, Cano, McLeod, &amp; Coon, <a href="references.html#ref-Petrillo2015" role="doc-biblioref">2015</a>; Raykov et al., <a href="references.html#ref-Raykov2010" role="doc-biblioref">2010</a>; Rusch et al., <a href="references.html#ref-Rusch2017" role="doc-biblioref">2017</a>)</span>. The latent variable approach is not too concerned with the <em>true</em> score -although it can be estimated- but with the extent to which a measure reflects the construct. Furthermore, it acknowledges explicitly that in social sciences we work most of the time with discrete data and it is not necessary to assume approximate continuity <span class="citation">(Raykov et al., <a href="references.html#ref-Raykov2010" role="doc-biblioref">2010</a>)</span>. So how latent variable modelling thinks about reliability?</p>
<p>One common thing between CTT and the approach based on latent variables is that both assume that observed indicators are outcomes of an underlying phenomenon or cause. However, the latent variable approach does relies on the idea of a <em>true</em> score as it does CTT. Instead, the concern of latent variable modelling is the extent to which the construct explains the variation of the observed item or set of items. Thus, the connection between CTT and latent variable modelling is the idea that outcome indicators are manifests of an underlying phenomenon but deal differently with uncertainty. This leads us to our measurement model for poverty show in Chapter 2 with equations <a href="Chapter-2.html#eq:model1">(2.2)</a> and <a href="Chapter-2.html#eq:model2">(2.3)</a>.</p>
<p><span class="math display">\[\begin{equation}
 x_{ij} = \lambda_{ij} \eta_j + \varepsilon_ij   
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
 \eta_j = \gamma_{j} \zeta  + \xi
\end{equation}\]</span></p>
<p>To keep it simple, for a unidimensional model (we will see below the formulation for multidimensional models) the factor loadings tells us the variance of the indicator accounted by for the latent construct. Thus, we have an equivalent expression for reliability under latent variable modelling:</p>
<p><span class="math display" id="eq:reliability2">\[\begin{equation}
\tag{3.3}
\rho_{x_{i}\theta} = \frac{\lambda^2_{i}} {\sigma^{2}_{xi}}
\end{equation}\]</span></p>
<p>Here the factor loadings <span class="math inline">\(\lambda_i\)</span>’s (here the <em>i</em>’s are just the items of the test <em>x</em>, as in CTT) are key in that they reflect the association between an outcome and the latent construct (explained variance by the factor). Therefore, latent variable approach naturally accommodates the issue about the observed variability of the manifest variables. The more the factor explains the variability of the manifest indicator -i.e. the more a deprivation indicator is caused by (and exclusively) poverty- the lower the error will be and the high the item-level reliability will be.</p>
<p>The use of such a powerful statistical infraestructure allows latent variable modelling to go beyond the capacities of CTT. This is a key point as it illustrates the power of using models (both in the theoretical and statistical sense) to inspect our poverty measures. Latent variable modelling is much more powerful and flexible than CTT. Extensions of the latent variable approach allow for non-linear relationships (like Item Response Theory); it is possible to estimate the underlying/latent score; the parameters are not dependent of the sample being used; items are selected based on a desired model; key parameters like <span class="math inline">\(\sigma^{2}_{x}\)</span> and <span class="math inline">\(\sigma^{2}_{e}\)</span> can be estimated and not assumed like in CTT <span class="citation">(Raykov et al., <a href="references.html#ref-Raykov2010" role="doc-biblioref">2010</a>; Rusch et al., <a href="references.html#ref-Rusch2017" role="doc-biblioref">2017</a>)</span>.</p>
</div>
<div id="Chapter-3-measuresrel" class="section level2">
<h2><span class="header-section-number">3.3</span> Statistical measures of reliability</h2>
<p>There are different ways to estimate the reliability of a scale, each one with its advantages and disadvantages. The most widely used estimator/index of reliability is <span class="math inline">\(\alpha\)</span> or <span class="math inline">\(\lambda_3\)</span> (do not mistake with factor loadings) <span class="citation">(Cronbach, <a href="references.html#ref-Cronbach1951" role="doc-biblioref">1951</a>; Guttman, <a href="references.html#ref-Guttman1945" role="doc-biblioref">1945</a>)</span>. This estimate comes from CTT and draws upon <span class="citation">Spearman (<a href="references.html#ref-Spearman1904" role="doc-biblioref">1904</a>)</span> approach to estimate the variance based on parallel tests and, more importantly, the idea that by correcting the value of a correlation by <em>attenuation</em> would lead to the best estimate of reliability. In other words: Are the observed correlations the true correlations? How this relationship is attenuated by noise?
This is a quite clever approach in that it tackled the problem of assessing consistency with just one test and allowed to include the effect of error upon item’s correlations. Ideally, we would like to have data for the same sample twice, so that we can compare how different our results are and thus how unstable our test is. Furthermore, we would like to estimate the variance of the true score and the variance of the observed score (<span class="math inline">\(\sigma^{2}_{\theta}\)</span> and <span class="math inline">\(\sigma^{2}_{x}\)</span>). But this is rarely the case. So, drawing upon <span class="citation">Spearman (<a href="references.html#ref-Spearman1904" role="doc-biblioref">1904</a>)</span>, <span class="citation">Cronbach (<a href="references.html#ref-Cronbach1951" role="doc-biblioref">1951</a>)</span> devised a formula to approximate the idea of parallel tests:</p>
<p><span class="math display" id="eq:alpha">\[\begin{equation}
\tag{3.4}
\alpha = \lambda_3 = \frac{\sigma^{2}_{x} - \sum\sigma^{2}_{xi}} {\sigma^{2}_{x}} \frac{n} {n-1}
\end{equation}\]</span></p>
<p>Cronbach’s <span class="math inline">\(\alpha\)</span> is, nonetheless, not a good estimate of reliability <span class="citation">(Revelle &amp; Zinbarg, <a href="references.html#ref-Revelle2009" role="doc-biblioref">2009</a>; Zinbarg, Revelle, Yovel, &amp; Li, <a href="references.html#ref-Zinbarg2005" role="doc-biblioref">2005</a>)</span>. It only works fine under very restrictive assumptions. First, the association between each indicator and the latent variable is equal. For example, for a measure based on three outcome variables it would mean that: <span class="math inline">\(\lambda_1=\lambda_2=\lambda_3\)</span>. Second, it assumes that the variances across tests are equal. These two assumptions are, however, necessary because otherwise it is not possible to compute <span class="math inline">\(\sigma^{2}_{\theta}\)</span>, <span class="math inline">\(\sigma^{2}_{x}\)</span> and the covariances. These two assumptions are unlikely to hold in practice. Another problem with <span class="math inline">\(\alpha\)</span> is that increasing the number of items and the average inter-item correlation will increase the reliability estimate. Table <a href="#ta:reliabilitystats"><strong>??</strong></a>* summarises the relation among the different reliability statistics by dimensionality.</p>
<p>Given that <span class="math inline">\(\alpha\)</span> is based upon untenable assumptions, there have been several proposals to estimate reliability under more general conditions. <span class="citation">Revelle (<a href="references.html#ref-Revelle1979" role="doc-biblioref">1979</a>)</span> proposes the statistic <span class="math inline">\(\beta\)</span>. This coefficient rather than being an substitute of <span class="math inline">\(\alpha\)</span> is a measure that provides information of how low the reliability is likely to be. Low in terms of heterogeneity, i.e. it examines what is the effect of the indicator with the lowest correlation upon reliability. Formally, <span class="math inline">\(\beta\)</span> considers the worse split in different halves, i.e. it minimizes the average covariance by taking into account the lowest inter-item correlation (<span class="math inline">\(\bar{\sigma_{ij}}\)</span>). It is thus a measure of the lowest possible reliability and therefore it will always be lower or equal to <span class="math inline">\(\alpha\)</span>. It is estimated as follows:</p>
<p><span class="math display" id="eq:beta">\[\begin{equation}
\tag{3.5}
 \beta = \frac{k^2 \bar{\sigma_{ij}}} {\sigma^{2}_{x}}
\end{equation}\]</span></p>
<p>Moving beyond CTT, <span class="citation">McDonald (<a href="references.html#ref-McDonald1999" role="doc-biblioref">1999</a>)</span> put forward two alternate measures of reliability: <span class="math inline">\(\omega\)</span> and <span class="math inline">\(\omega_h\)</span>. The statistics can be better framed within latent variable modelling and thus are estimated using factor analysis -preferably confirmatory factor analysis (<span class="citation">Brown (<a href="references.html#ref-Brown2006" role="doc-biblioref">2006</a>)</span>), see section <a href="Chapter-3.html#relestimation">3.5</a>-. Both use the idea expressed in equation <a href="Chapter-3.html#eq:reliability2">(3.3)</a>, i.e. the variance of the outcome measure accounted by for the factor for each indicator and then aggregates this to produce indices for the scale as a whole. The first statistic ( <span class="math inline">\(\omega\)</span>) is also know as the measure that maximizes the estimation of reliability, i.e. the lowest upper bound <span class="citation">(Zinbarg et al., <a href="references.html#ref-Zinbarg2005" role="doc-biblioref">2005</a>)</span>. Equation <a href="Chapter-3.html#eq:omega">(3.6)</a> shows the formula of <span class="math inline">\(\omega\)</span>. This equation is a proportion of the variance of the outcome measures that is explained by the factor. In other words, if we have several very good deprivation indicators that are caused by the lack of command of resources over time, we expect the error to be low and the loadings of each indicator to be very high. Consequently, <span class="math inline">\(\omega\)</span> will be very high, i.e. close to 1, which is its maximum value.</p>
<p><span class="math display" id="eq:omega">\[\begin{equation}
\tag{3.6}
 \omega = \frac{ \sum\limits_{j=1}^k  \bigg(\sum\limits_{i=1}^p \lambda_{ij}\bigg)^2 } {\sum\limits_{j=1}^k  \bigg(\sum\limits_{i=1}^p \lambda_{ij}\bigg)^2 + \sum\limits_{i=1}^p e_i}
\end{equation}\]</span></p>
<p>The statistic <span class="math inline">\(\omega\)</span> focuses on the unidimensional case in that it main concern is working out the percentage of the variance explained by the factor. However, in multidimensional poverty measurement we have a higher-order factor and several nested factors (dimensions of poverty). Thus, there we have at least to sets of relationship in the multidimensional case: (1) The relationship between each outcome measure and the overall factor (poverty) and (2) the relationship between each dimension and its outcome measures. In fact, this is more complex that it seems, as the first relationship can be also put in terms of the relationship between the higher-order factor and each dimension.</p>
<p>The answer to the problem of nested dimensions for the computation of reliability is <span class="math inline">\(\omega_h\)</span>. Equation <a href="Chapter-3.html#eq:omegah">(3.7)</a> shows the formula to estimate this statistic. It is a hierarchical version of <span class="math inline">\(\omega\)</span> in that it aims to estimate the two sets of relationships stated above: the variance of the indicators explained by both the higher order factor and the subdimensions. The best way to estimate <span class="math inline">\(\omega_h\)</span> is by using the <span class="citation">Schmid &amp; Leiman (<a href="references.html#ref-Schmid1957" role="doc-biblioref">1957</a>)</span> transformation (see an example <span class="citation">(Wolff &amp; Preising, <a href="references.html#ref-Wolff2005" role="doc-biblioref">2005</a>)</span> and section (<a href="Chapter-3.html#relestimation">3.5</a>)). This is relatively simple procedure that transforms a higher-order factor model (general factor model) into a model where the loadings of the outcome measures are explicitly computed for both the higher-order factor and the subfactors or dimensions. Therefore, this is a more appropriate measure when having multidimensional scales.</p>
<p><span class="math display" id="eq:omegah">\[\begin{equation}
\tag{3.7}
\omega_h = \frac{  \bigg(\sum\limits_{i=1}^p \lambda_{ij}\bigg) ^2 } {\sum\limits_{j=1}^k  \bigg(\sum\limits_{i=1}^p \lambda_{ij}\bigg) ^2 + \sum\limits_{i=1}^p e_i}
\end{equation}\]</span></p>
<p>These different reliability statistics beg the following question: Which one should be used? There are two complementary ways to answer this question. First, these reliability statistics are based on a series of assumptions and thus its usage depends on the extent to which each one is adequate given the data and the research question.</p>
<p><span class="math inline">\(\alpha\)</span> is a very specific case whose assumptions will be rarely meet in practice. The recommendation is to avoid using <span class="math inline">\(\alpha\)</span> and focus on general cases such as <span class="math inline">\(\omega\)</span> and <span class="math inline">\(\omega_h\)</span>. <span class="math inline">\(\omega\)</span> will work in almost any situation but when the measures are multidimensional. This does not mean that it would be incorrect to use it. In multidimensional settings, <span class="math inline">\(\omega_h\)</span> is just more adequate because it will tell the amount of variance accounted by for the higher order factor.</p>
<p><span class="citation">Zinbarg et al. (<a href="references.html#ref-Zinbarg2005" role="doc-biblioref">2005</a>)</span> ran a Monte Carlo study to assess how does the different reliability statistics compare one another. They found the following (See Table <a href="Chapter-3.html#tab:reliabilitystats">3.1</a>):</p>
<table>
<caption><span id="tab:reliabilitystats">Table 3.1: </span> Summary of the relations among <span class="math inline">\(\beta\)</span>, <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\omega\)</span> and
reliability depending on index dimensionality. Taken from <span class="citation">(Zinbarg et al., <a href="references.html#ref-Zinbarg2005" role="doc-biblioref">2005</a>, p. 128)</span></caption>
<thead>
<tr class="header">
<th align="center">Dimensionality</th>
<th align="center">Expected behaviour</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Multidimensional</td>
<td align="center"><span class="math inline">\(\beta&lt;\alpha&lt;\omega\leq\rho\)</span></td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center"><span class="math inline">\(\omega_h&lt;\omega\leq\rho\)</span></td>
</tr>
<tr class="odd">
<td align="center">Unidimensional</td>
<td align="center"><span class="math inline">\(\beta&lt;\alpha&lt;\omega_h=\omega\leq\rho\)</span></td>
</tr>
</tbody>
</table>
<hr />
<p>The second way to answer the question has to do with the conclusions one could make from the estimation of these measures. If the assumptions are violated our conclusions would be very likely incorrect and misleading. Assuming the correct statistic is selected, the question is: How low is too low to be unacceptable?</p>
<p>One of the consequences of reliability is that it leads to an accurate ranking or ordering of the population in question, i.e. from the lowest standard of living to the highest. <span class="citation">Nájera (<a href="references.html#ref-Najera2018" role="doc-biblioref">2018</a>)</span> run a Monte Carlo study to assess the relationship between reliability and population classification. Hence, this study poses the question about the level of reliability that guarantees a low amount of error. The result was that there is a clear relationship between reliability and population classification. The summary of the findings of <span class="citation">Nájera (<a href="references.html#ref-Najera2018" role="doc-biblioref">2018</a>)</span> are shown in Table <a href="Chapter-3.html#tab:relentropy">3.2</a>. The simulation considered three possible dimensional structures: unidimensional, weak and strong multidimensional measures. Weak multidimensionality was defined as the case where the dimensions have relatively low loadings to the higher-order factor.</p>
<table style="width:86%;">
<caption><span id="tab:relentropy">Table 3.2: </span> Summary of the relations among
<span class="math inline">\(\beta\)</span>, <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\omega\)</span> and entropy depending on index
dimensionality. Summarised from <span class="citation">Nájera (<a href="references.html#ref-Najera2018" role="doc-biblioref">2018</a>)</span>.
In this case, the unidimensional model seem to meet
<span class="math inline">\(\tau\)</span> equivalence, i.e. equal loadings.</caption>
<colgroup>
<col width="23%" />
<col width="16%" />
<col width="31%" />
<col width="13%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left">Reliabiity
statistic</td>
<td align="center">Leads to</td>
<td align="center">lassification error
(%)</td>
<td align="center">Entropy
value</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\alpha&gt;.8\)</span></td>
<td align="center"><span class="math inline">\(\approx\)</span></td>
<td align="center"><span class="math inline">\(&lt;5\%\)</span></td>
<td align="center"><span class="math inline">\(&gt;.8\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\omega&gt;.8\)</span></td>
<td align="center"><span class="math inline">\(\approx\)</span></td>
<td align="center"><span class="math inline">\(&lt;5\%\)</span></td>
<td align="center"><span class="math inline">\(&gt;.8\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\omega&gt;.85\)</span></td>
<td align="center"><span class="math inline">\(\approx\)</span></td>
<td align="center"><span class="math inline">\(&lt;5\%\)</span></td>
<td align="center"><span class="math inline">\(&gt;.8\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\omega_h&gt;.65\)</span></td>
<td align="center"><span class="math inline">\(\approx\)</span></td>
<td align="center"><span class="math inline">\(&lt;5\%\)</span></td>
<td align="center"><span class="math inline">\(&gt;.8\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\omega&gt;.85\)</span></td>
<td align="center"><span class="math inline">\(\approx\)</span></td>
<td align="center"><span class="math inline">\(&lt;5\%\)</span></td>
<td align="center"><span class="math inline">\(&gt;.8\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\omega_h&gt;.70\)</span></td>
<td align="center"><span class="math inline">\(\approx\)</span></td>
<td align="center"><span class="math inline">\(&lt;5\%\)</span></td>
<td align="center"><span class="math inline">\(&gt;.8\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="itemlevelrel" class="section level2">
<h2><span class="header-section-number">3.4</span> Item-level reliability and weighting</h2>
<p>Classical test theory was concerned with overall reliability. Item response theory (IRT) moved from the idea of a true score and look at the relationship of the indicators with an underlying trait (e.g. intelligence, depression, poverty) <span class="citation">(Harris, <a href="references.html#ref-Harris1989" role="doc-biblioref">1989</a>)</span>. IRT is a theory about the type of relationship that an indicator has with a latent variable. The simplest IRT specification proposes that a measure is unidimensional (i.e. the variance of the indicators is accounted by for one trait) and that each item relates to different degrees of difficulty or severity of the construct. This is called a one-parameter IRT model. A more general IRT model also proposes that some indicators are better than others to differentiate the population. That is, that some deprivation indicators are associated with a higher likelihood of belonging to the poor group. This more general aspect is added via a second parameter called discrimination and leads to a two-parameter IRT model. This kind of model has been used by <span class="citation">Guio et al. (<a href="references.html#ref-Guio2016" role="doc-biblioref">2016</a>)</span> and <span class="citation">Guio et al. (<a href="references.html#ref-Guio2017" role="doc-biblioref">2017</a>)</span> for example.</p>
<p><span class="math display" id="eq:irt">\[\begin{equation}
\tag{3.8}
P_i\theta = \frac{1} {1+e^{-1.7a_i(\theta-b_i)}}
\end{equation}\]</span></p>
<p>Equation <a href="Chapter-3.html#eq:irt">(3.8)</a>, translated to poverty measurement, states that the probability of choosing a someone that is deprived in the indicator <span class="math inline">\(i\)</span> is given by the discrimination (a) and the severity(b) of the item. <span class="citation">Muthén (<a href="references.html#ref-Muthen2013" role="doc-biblioref">2013</a>)</span> show how this model relates to a unidimensional factor model, equations 21 and 22. In a factor model (b) is just a threshold and (a) the factor loadings (<span class="math inline">\(\lambda_{i}\)</span>). Therefore, the stronger the loadings, the higher its discrimination power, where <span class="math inline">\(\psi\)</span> is the variance of the latent variable.</p>
<p><span class="math display" id="eq:irta">\[\begin{equation}
\tag{3.9}
 a_{i}=\lambda_{i}\sqrt{\psi} 
\end{equation}\]</span></p>
<p>The original IRT models work under the assumption of unidimensional scales, i.e. one factor with several manifest variables that exclusively belonged to such factor. However, this is no longer the case as it is possible to estimate multidimensional IRT model <span class="citation">(Reckase, <a href="references.html#ref-Reckase2009" role="doc-biblioref">2009</a>)</span>. However, <span class="citation">Gibbons, Immekus, Bock, &amp; Gibbons (<a href="references.html#ref-Gibbons2007" role="doc-biblioref">2007</a>)</span> have shown that the presence of a higher-order factor produces little bias in the estimates when having more dimensions. In theory, all multidimensional poverty models make such an assumption. In any case, the concepts remain the same and a multidimensional IRT model can be simply connected with multidimensional confirmatory factor model.</p>
<p>Statistics such as <span class="math inline">\(\beta\)</span>, <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\omega\)</span> provide an summary of the overall reliability. The computation of <span class="math inline">\(\omega\)</span> heavily relies on the factor loadings. The lower the factor loadings the higher the error and the lower the overall reliability. Similarly, low <span class="math inline">\(\lambda_{i}\)</span> can be translated as low item-level reliability values. The question is thus how low mean unreliable. <span class="citation">Guio et al. (<a href="references.html#ref-Guio2016" role="doc-biblioref">2016</a>)</span> use the rule of <span class="math inline">\(&lt;.4\)</span> standardised loadings as a measure of item-unreliability. <span class="citation">Nájera (<a href="references.html#ref-Najera2018" role="doc-biblioref">2018</a>)</span> shows that indeed those values are more likely to result in overall unreliability and high population classification error.</p>
<p>One of the most contested issues in poverty measurement revolves around weighting <span class="citation">(Decancq &amp; Lugo, <a href="references.html#ref-Decancq2013" role="doc-biblioref">2013</a>)</span>. Measurement theory proposes that reliability lead to a self-weighting measure in that it guarantees good population classification <span class="citation">(Streiner et al., <a href="references.html#ref-Streiner2015" role="doc-biblioref">2015</a>)</span>. Discrimination parameters have a crucial role upon population classification and item weighting. The square of the factor loadings equals the amount of variance in the indicator explained by the common factor (i.e. communality). Because the factor loadings capture the relationship of each indicator with the latent variable, they can be seen as the optimal weights of the model given the data. Therefore, a test of equality of loadings within dimensional can be used to assess whether using such kind of weighting is reasonable or not. <span class="citation">Nájera (<a href="references.html#ref-Najera2018" role="doc-biblioref">2018</a>)</span> shows that very high reliability leads to a self-weighting index in that the population ranking is less sensible to the items used in a scale. Therefore, discussing the use of differential weights versus non-differential weights misses the point. The critical point is that differential weights, in that they are unknown, will always introduce more noise to the classification of the population. Whereas reliability is a necessary condition for good population orderings, weighting it is not so.</p>
<p>One of the key axioms in poverty research is the monotonicity axiom. It states that poverty <em>ceteris paribus</em> should decrease after an improvement in one’s achievements <span class="citation">(Alkire et al., <a href="references.html#ref-Alkire2015" role="doc-biblioref">2015</a>; Sen, <a href="references.html#ref-Sen1976" role="doc-biblioref">1976</a>)</span>. Measurement theory states something very similar in that low loadings reflect the fact that changes in the latent variable do not lead to changes in observed deprivation. <span class="citation">Nájera (<a href="references.html#ref-NajeraForthcoming" role="doc-biblioref">n.d.</a>)</span> ran a Monte Carlo experiment the particularities of this behaviour. He finds that item-level unreliability leads to a violation of the monotonicity axiom. His conclusion is that indicators that have weak discrimination <span class="math inline">\(\lambda_ij&lt;.4\)</span> (standardised loadings) violate weak monotonicity and in some circumstances could violate strong monotonicity. Therefore, such indicators are more noise than signal to poverty measures.</p>
</div>
<div id="relestimation" class="section level2">
<h2><span class="header-section-number">3.5</span> Estimation of Reliability</h2>
<div id="overall-reliability" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Overall reliability</h3>
<p>To introduce the idea of reliability we will use the data set “Rel_MD_data_1_1.dat”. This is simulated data of a higher-order multidimensional measure of poverty (<span class="math inline">\(n=5000\)</span>). The measure has nine indicators in total, distributed evenly in three dimensions.</p>
<p>We will start using <strong>R-software</strong> for the estimation of reliability. The data was simulated in <strong>Mplus 8</strong> <span class="citation">(Muthén &amp; Muthén, <a href="references.html#ref-Muthen2012" role="doc-biblioref">2012</a>)</span>. We will read the file “Rel_MD_data_1_1.dat” using the <code>read.table()</code> function in R, with the option <code>header=TRUE</code> so that it reads the name of the variables. We ask R to store this on <code>Rel_MD_1</code> for easy access and manipulations. Now we will explore the contents of this data set with <code>str()</code> to see which variables we have. We have 11 binary variables (deprivation indicators) and then we have some ancilliary data that we will use later for some computations. We have 11 binary variables but above we said that the index has 9 indicators. We will use x10 and x11 below but for now focus on x1-x9.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(plyr)
Rel_MD_<span class="dv">1</span>&lt;-<span class="kw">read.table</span>(<span class="st">&quot;Rel_MD_data_1_1.dat&quot;</span>)
<span class="kw">colnames</span>(Rel_MD_<span class="dv">1</span>)&lt;-<span class="kw">c</span>(<span class="st">&quot;x1&quot;</span>,<span class="st">&quot;x2&quot;</span>,<span class="st">&quot;x3&quot;</span>,<span class="st">&quot;x4&quot;</span>,<span class="st">&quot;x5&quot;</span>,<span class="st">&quot;x6&quot;</span>,
                      <span class="st">&quot;x7&quot;</span>,<span class="st">&quot;x8&quot;</span>,<span class="st">&quot;x9&quot;</span>,<span class="st">&quot;x10&quot;</span>,<span class="st">&quot;x11&quot;</span>,
                      <span class="st">&quot;resources&quot;</span>,<span class="st">&quot;educ_yr&quot;</span>,<span class="st">&quot;occupation&quot;</span>,<span class="st">&quot;hh_members&quot;</span>,<span class="st">&quot;class&quot;</span>)
<span class="kw">str</span>(Rel_MD_<span class="dv">1</span>)</code></pre>
<pre><code>## &#39;data.frame&#39;:    5000 obs. of  16 variables:
##  $ x1        : int  1 0 0 1 1 1 0 0 1 0 ...
##  $ x2        : int  1 0 0 1 0 0 0 0 0 0 ...
##  $ x3        : int  1 0 0 0 0 0 0 0 0 0 ...
##  $ x4        : int  1 0 1 0 0 0 1 1 1 0 ...
##  $ x5        : int  0 0 0 0 0 0 0 0 1 0 ...
##  $ x6        : int  0 0 0 0 0 0 1 0 1 0 ...
##  $ x7        : int  0 0 0 1 0 0 0 0 1 0 ...
##  $ x8        : int  0 0 0 0 0 0 0 0 1 0 ...
##  $ x9        : int  0 0 0 0 0 0 0 0 1 0 ...
##  $ x10       : int  0 0 0 0 1 0 0 1 0 1 ...
##  $ x11       : int  0 0 0 0 1 0 0 1 0 0 ...
##  $ resources : num  3277 7509 7184 1574 2210 ...
##  $ educ_yr   : int  6 15 8 6 9 13 12 7 7 6 ...
##  $ occupation: int  4 2 5 2 5 5 6 7 5 3 ...
##  $ hh_members: int  5 1 2 7 4 4 2 4 1 3 ...
##  $ class     : int  2 1 1 2 2 1 1 2 2 2 ...</code></pre>
<p>Below we ask R to shown the first ten rows of our data set (the nine deprivation vars). Prior the analysis we need to conduct some basic inspections. We can compute a simple deprivation score/count called <code>ds</code> by applying <code>rowSums()</code> to the first nine items (x1-x9).</p>
<pre class="sourceCode r"><code class="sourceCode r">Rel_MD_<span class="dv">1</span>[<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">11</span>]</code></pre>
<pre><code>##    x1 x2 x3 x4 x5 x6 x7 x8 x9 x10 x11
## 1   1  1  1  1  0  0  0  0  0   0   0
## 2   0  0  0  0  0  0  0  0  0   0   0
## 3   0  0  0  1  0  0  0  0  0   0   0
## 4   1  1  0  0  0  0  1  0  0   0   0
## 5   1  0  0  0  0  0  0  0  0   1   1
## 6   1  0  0  0  0  0  0  0  0   0   0
## 7   0  0  0  1  0  1  0  0  0   0   0
## 8   0  0  0  1  0  0  0  0  0   1   1
## 9   1  0  0  1  1  1  1  1  1   0   0
## 10  0  0  0  0  0  0  0  0  0   1   0</code></pre>
<p>Now we can check the proportion of people deprived of each indicator as follows. First, we will ask R to estimate the <code>mean()</code> for all indicators and store this information on <code>dep_prop</code>. Then we will request R to round them up but only for the nine deprivation indicators. We see that 50% of people in this sample lack x1, for example.</p>
<pre class="sourceCode r"><code class="sourceCode r">dep_prop&lt;-<span class="kw">unlist</span>(<span class="kw">lapply</span>(Rel_MD_<span class="dv">1</span>, <span class="cf">function</span>(x) <span class="kw">mean</span>(x)))
dep_prop&lt;-<span class="kw">round</span>(dep_prop[<span class="dv">1</span><span class="op">:</span><span class="dv">9</span>]<span class="op">*</span><span class="dv">100</span>,<span class="dv">0</span>)
dep_prop</code></pre>
<pre><code>## x1 x2 x3 x4 x5 x6 x7 x8 x9 
## 50 29 16 49 29 16 45 26 16</code></pre>
</div>
<div id="Chapter-3-expoverel" class="section level3">
<h3><span class="header-section-number">3.5.2</span> Exploratory (non-model based) estimation of overall reliability</h3>
<p>Now that we have familiarised with the data ourselves we can proceed to check the reliability of this scale. In this section we will focus on the case where we do not have a poverty measure model (i.e. we have a list of indicators but we do not have a structure). Reliability concerns with the homogeneity of a scale and its capacity to produce consistent rankings of a population. We will start by estimating the overall reliability of our scale using the <code>psych</code> package <span class="citation">(Revelle, <a href="references.html#ref-Revelle2014" role="doc-biblioref">2014</a>)</span>. This is a comprehensive R-package to estimate different reliability statistics (<span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, <span class="math inline">\(\omega\)</span> and <span class="math inline">\(\omega_h\)</span>) under different changing conditions. The <code>psych</code> package can be used for exploratory and confirmatory settings for both unidimensional and multidimensional measures. This book focuses on confirmatory measurement models and to introduce the estimation of overall reliability we will rely on the simplest way to estimate the homogeneity of a scale using the simulated data set. This will be further developed, and the next section shows how <code>psych</code> interacts with another R-package <code>lavaan</code> to estimate <span class="math inline">\(\omega\)</span> and <span class="math inline">\(\omega_h\)</span> from a confirmatory factor model <span class="citation">(Rosseel, <a href="references.html#ref-Rosseel2012" role="doc-biblioref">2012</a>)</span>.</p>
<p>The <code>pysch</code> package permits estimating <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\omega\)</span> using the same function (<code>omega</code>). The package has several options, but we know that there are three dimensions and one higher order factor and these values match the defaults of the <code>omega</code> function. It is important to bear in mind that in this simple case the value of <span class="math inline">\(\omega\)</span> is approximated with an Exploratory Factor Analysis (EFA). Below is shown how to do it with a confirmatory model.</p>
<p>After applying the <code>omega()</code> to our nine indicators, there will be different objects that store information with the results of the analysis. We will focus on the overall estimate of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\omega\)</span> as here we are interested in knowing the homogeneity of our scale. To extract the relevant estimates we will produce a <code>data.frame</code> that contains the results from <code>omega_exp1</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># install.packages(&quot;psych&quot;)</span>
<span class="kw">require</span>(psych)
omega_exp1&lt;-<span class="kw">omega</span>(Rel_MD_<span class="dv">1</span>[,<span class="kw">c</span>(<span class="dv">3</span><span class="op">:</span><span class="dv">9</span>)])
rel_uni_exp&lt;-<span class="kw">data.frame</span>(<span class="dt">omega_exp1=</span>omega_exp1<span class="op">$</span>omega.tot, 
                        <span class="dt">alpha=</span>omega_exp1<span class="op">$</span>alpha)
rel_uni_exp</code></pre>
<pre><code>##   omega_exp1     alpha
## 1  0.8599319 0.8127129</code></pre>
<p>We can appreciate below that both values are high (<span class="math inline">\(\geq.8\)</span>) (See section <a href="Chapter-3.html#Chapter-3-measuresrel">3.3</a> for an explanation) and suggest that the scale is highly reliable. In this case, <span class="math inline">\(\alpha&lt;\omega\)</span> indicating that this scale violates <span class="math inline">\(\tau\)</span> equivalence (equality of loadings).</p>
<p>Both <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\omega\)</span> are easily estimated with the <code>psych</code> package. However, the previous example was straightforward in that all the indicators are well-behaved. Thus, to gain a deeper understanding of reliability and population classification we will check what happens when one has indicators that reduce reliability. This can be done by adding noise to our measure. We will generate two uncorrelated indicators and substitute x10 and x11 for the indicators x1 and x2.</p>
<p>Then we can apply <code>omega()</code> to the new matrix that includes V1 and v1 and excludes x1 and x2. Reliability has drop slightly but enough to raise concerns as both <span class="math inline">\(\omega\)</span> and <span class="math inline">\(\alpha\)</span> are below the rules of thumb drawn from a Monte Carlo experiment.</p>
<pre class="sourceCode r"><code class="sourceCode r">omega_unr_exp&lt;-<span class="kw">omega</span>(Rel_MD_<span class="dv">1</span>[,<span class="kw">c</span>(<span class="dv">3</span><span class="op">:</span><span class="dv">11</span>)])
unrel_uni_exp&lt;-<span class="kw">data.frame</span>(<span class="dt">omega_exp=</span>omega_unr_exp<span class="op">$</span>omega.tot, 
                          <span class="dt">alpha=</span>omega_unr_exp<span class="op">$</span>alpha)
unrel_uni_exp</code></pre>
<pre><code>##   omega_exp    alpha
## 1  0.799405 0.738685</code></pre>
<p>What is the impact of introducing the two uncorrelated indicators? From theory is known that losses in reliability affect the consistency of population classification. We can check if this theory holds by looking at the correlation of different rankings that are produce from different measures. For this experiment, first, we will estimate the omega values using different combinations of items (in all case we have the seven items from the reliable measure x1-x9).</p>
<pre class="sourceCode r"><code class="sourceCode r">omega_exp2&lt;-<span class="kw">omega</span>(Rel_MD_<span class="dv">1</span>[,<span class="kw">c</span>(<span class="dv">3</span><span class="op">:</span><span class="dv">9</span>)])
omega_exp3&lt;-<span class="kw">omega</span>(Rel_MD_<span class="dv">1</span>[,<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">7</span>,<span class="dv">8</span>)])
omega_exp4&lt;-<span class="kw">omega</span>(Rel_MD_<span class="dv">1</span>[,<span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">8</span>,<span class="dv">9</span>)])
omega_exp5&lt;-<span class="kw">omega</span>(Rel_MD_<span class="dv">1</span>[,<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">9</span>)])


omegas_exp&lt;-<span class="kw">data.frame</span>(<span class="dt">omega_exp1=</span>omega_exp1<span class="op">$</span>omega.tot, 
                       <span class="dt">omega_exp2=</span>omega_exp2<span class="op">$</span>omega.tot,
                       <span class="dt">omega_exp3=</span>omega_exp3<span class="op">$</span>omega.tot, 
                       <span class="dt">omega_exp4=</span>omega_exp4<span class="op">$</span>omega.tot, 
                       <span class="dt">omega_exp5=</span>omega_exp5<span class="op">$</span>omega.tot, 
                       <span class="dt">omega_unrel=</span>omega_unr_exp<span class="op">$</span>omega.tot)</code></pre>
<p>We then can compare the omega values of each measure. The theory holds for this example. We see that the lowest reliability scale is the one that incorporates V1 and V2. The measures with only seven items have higher reliability. This is a very important lesson as poverty researchers sometimes keep unreliable indicators in their scales and the consequence will be a heavy loss in reliability.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t</span>(omegas_exp)</code></pre>
<pre><code>##                  [,1]
## omega_exp1  0.8599319
## omega_exp2  0.8599319
## omega_exp3  0.8779016
## omega_exp4  0.8543497
## omega_exp5  0.8441886
## omega_unrel 0.7994050</code></pre>
<p>The second prediction of reliability theory is that the population orderings are consistent for high reliability values. One way to check this is by estimating the correlation among the different deprivation scores. Again, the theory holds for this simple exercise, the measure with higher <span class="math inline">\(\omega\)</span> are highly correlated. The correlation of the unreliable measure seems still high, however, when <span class="math inline">\(\omega&lt;.8\)</span> we could expect to see a classification error <span class="math inline">\(&gt;5\%\)</span> which might be very worrying when put into perspective. If the poverty rate is <span class="math inline">\(20\%\)</span> and the classification error is <span class="math inline">\(5\%\)</span> it would mean that potentially a <span class="math inline">\(25\%\)</span> of the poor are mistakenly classified <span class="citation">(Nájera, <a href="references.html#ref-Najera2018" role="doc-biblioref">2018</a>)</span>.</p>
<p>Reliability will be affected by the items that we keep in our scale. To gain deeper understanding of how different sets of items affeect reliability we will use different combinations of items and then we will compute its reliability. First we will star by producing a deprivations score by using taking the sum of the nine reliable items with <code>rowSums</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">Rel_MD_<span class="dv">1</span><span class="op">$</span>ds&lt;-<span class="kw">rowSums</span>(Rel_MD_<span class="dv">1</span>[,<span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">9</span>)])</code></pre>
<p>We can inspect the distribution of this deprivation score by plotting it (Figure <a href="Chapter-3.html#fig:depscore">3.1</a>) as follows:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(ggplot2)
<span class="kw">ggplot</span>(Rel_MD_<span class="dv">1</span>, <span class="kw">aes</span>(ds)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_histogram</span>() <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>() <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Deprivation score&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">9</span>, <span class="dt">by =</span> <span class="dv">1</span>))</code></pre>
<div class="figure"><span id="fig:depscore"></span>
<img src="PM_Book_files/figure-html/depscore-1.png" alt="This is the histogram of the deprivation score. It shows the number of people by the equally weighted deprivation count." width="672" />
<p class="caption">
Figure 3.1: This is the histogram of the deprivation score. It shows the number of people by the equally weighted deprivation count.
</p>
</div>
<p>We see that our deprivation score looks inflated in the right and deflated on the left. This is the expected distribution of a deprivation score in that the majority of the population tends to lack fewer items. This could look very different in very poor countries where most of the population like the majority of basic needs.</p>
<p>To see the relationship between reliability and different scores, we will compute five more scores using different combinations of items. We will see if reliability is affected by the number of items. The correlation matrix shows that if we keep reliable items only, we will have very high correlation with the perfect measure, which in this case is the measure with the nine items (ds). However, we see that, the measure with unreliable items leads to a drop of .93. This is not too bad as <span class="math inline">\(\omega\)</span> remains high for this scale, but if we drop a couple of items we would see a major drop (.87) (see ds_unrel2).</p>
<pre class="sourceCode r"><code class="sourceCode r">Rel_MD_<span class="dv">1</span><span class="op">$</span>ds_r2&lt;-<span class="kw">rowSums</span>(Rel_MD_<span class="dv">1</span>[,<span class="kw">c</span>(<span class="dv">3</span><span class="op">:</span><span class="dv">9</span>)])
Rel_MD_<span class="dv">1</span><span class="op">$</span>ds_r3&lt;-<span class="kw">rowSums</span>(Rel_MD_<span class="dv">1</span>[,<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">7</span>,<span class="dv">8</span>)])
Rel_MD_<span class="dv">1</span><span class="op">$</span>ds_r4&lt;-<span class="kw">rowSums</span>(Rel_MD_<span class="dv">1</span>[,<span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">8</span>,<span class="dv">9</span>)])
Rel_MD_<span class="dv">1</span><span class="op">$</span>ds_r5&lt;-<span class="kw">rowSums</span>(Rel_MD_<span class="dv">1</span>[,<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">9</span>)])
Rel_MD_<span class="dv">1</span><span class="op">$</span>ds_ur&lt;-<span class="kw">rowSums</span>(Rel_MD_<span class="dv">1</span>[,<span class="kw">c</span>(<span class="dv">3</span><span class="op">:</span><span class="dv">9</span>,<span class="dv">10</span>,<span class="dv">11</span>)])
Rel_MD_<span class="dv">1</span><span class="op">$</span>ds_ur2&lt;-<span class="kw">rowSums</span>(Rel_MD_<span class="dv">1</span>[,<span class="kw">c</span>(<span class="dv">3</span><span class="op">:</span><span class="dv">7</span>,<span class="dv">10</span>,<span class="dv">11</span>)])

ds.m&lt;-(Rel_MD_<span class="dv">1</span>[,<span class="kw">c</span>(<span class="dv">17</span><span class="op">:</span><span class="dv">23</span>)])
ds.cor&lt;-<span class="kw">cor</span>(ds.m)
ds.cor</code></pre>
<pre><code>##               ds     ds_r2     ds_r3     ds_r4     ds_r5     ds_ur
## ds     1.0000000 0.9684719 0.9764524 0.9523882 0.9733462 0.9272651
## ds_r2  0.9684719 1.0000000 0.9284786 0.9370200 0.9485305 0.9520979
## ds_r3  0.9764524 0.9284786 1.0000000 0.8875033 0.9371505 0.8899044
## ds_r4  0.9523882 0.9370200 0.8875033 1.0000000 0.8876694 0.8941369
## ds_r5  0.9733462 0.9485305 0.9371505 0.8876694 1.0000000 0.9099612
## ds_ur  0.9272651 0.9520979 0.8899044 0.8941369 0.9099612 1.0000000
## ds_ur2 0.8700863 0.8860309 0.8437632 0.8124119 0.8690256 0.9628708
##           ds_ur2
## ds     0.8700863
## ds_r2  0.8860309
## ds_r3  0.8437632
## ds_r4  0.8124119
## ds_r5  0.8690256
## ds_ur  0.9628708
## ds_ur2 1.0000000</code></pre>
</div>
<div id="model-based-estimation-of-overall-reliability" class="section level3">
<h3><span class="header-section-number">3.5.3</span> Model-based estimation of overall reliability</h3>
<p>The ideal workflow in poverty measurement must include a clear specification of a measurement model. In both the theoretical and applied literature, different authors propose models that suggest that poverty is multidimensional and hierarchical (See Section <a href="Chapter-1.html#Chapter-1-dimensions">1.2</a>). Therefore, in multidimensional poverty measurement we will be almost always interested in assessing reliability using an a priori model and thus we will require to estimate both overall and hierarchical omega (<span class="math inline">\(\omega\)</span> and <span class="math inline">\(\omega_h\)</span>). These two can be estimated from an EFA using the R-package <code>psych</code>. However, this book aims to encourage poverty researchers to walk toward the production and assessment of theoretical models, rather than systematically inferring the structure from the data.</p>
<p>This section thus focuses on the examination of reliability when researchers have an a priori measurement model of poverty. Unlike the previous section, the following examples rely on Confirmatory Factor Analysis (CFA) <span class="citation">(Brown, <a href="references.html#ref-Brown2006" role="doc-biblioref">2006</a>)</span>. The key difference between an EFA and a CFA is that the second rely on a theoretical model that states the structure of a measure, i.e. a blueprint for measuring poverty (See Section <a href="Chapter-2.html#Chapter-2-blueprint">2.8</a>). A CFA model will examine the extent to which the theoretical model (i.e. number of dimensions, contents of dimensions-indicators, independence of dimensions) manages to reproduce the observed data.
In statistical terms, researchers provide a predefined pattern-loading specification. This is specified in equations <a href="Chapter-2.html#eq:model1">(2.2)</a> and <a href="Chapter-2.html#eq:model2">(2.3)</a>. This is just the mathematical formulation of the diagrams shown in section <a href="Chapter-2.html#Chapter-2-blueprint">2.8</a>.</p>
<p><span class="math display">\[\begin{equation}
 x_{ij} = \lambda_{ij} \eta_j + \varepsilon_ij   
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
 \eta_j = \gamma_{j} \zeta  + \xi
\end{equation}\]</span></p>
<p>Reliability is estimated after a CFA model because both <span class="math inline">\(\omega\)</span> and <span class="math inline">\(\omega_h\)</span> rely on two key pieces of information of a CFA model: The factor loadings and the errors. That is, item-factor loadings and the residuals of the model are the key parameters for the estimation of both reliability statistics (See equation <a href="Chapter-3.html#eq:omega">(3.6)</a>).</p>
<p>In the following we will show how in both <strong>Mplus</strong> and <strong>R</strong> is possible to estimate <span class="math inline">\(\omega\)</span> and <span class="math inline">\(\omega_h\)</span>. We will start with R and for this purpose we need the <code>lavaan</code> package <span class="citation">(Rosseel, <a href="references.html#ref-Rosseel2012" role="doc-biblioref">2012</a>)</span>. This package comprises a series of functions to estimate different kinds of latent variable models such as measurement and analytic models like Structural Equation Models (SEM). Once the CFA model is fitted with the R-package <code>lavaan</code>, the function <code>omegaFromSem()</code> of the <code>psych</code> R-package can be used to estimate <span class="math inline">\(\omega\)</span> and <span class="math inline">\(\omega_h\)</span>. However, we will show how this can be done by hand to gain insight of the differences between the two reliability statistics and to operationalise the process using the <strong>Mplus</strong> estimates.</p>
<div id="computation-using-r" class="section level4">
<h4><span class="header-section-number">3.5.3.1</span> Computation using R</h4>
<p>We will continue using our simulated data (“Rel_MD_data_1_1.dat”). As a remainder we have stored the data on the object <code>Rel_MD_1</code> (see above). So the first question we need to answer is <em>What is the structure of our measure?</em>. That is, how many dimensions and how many indicators (and which indicators) for each dimension. In this case, we will assume that our theory tells us that we have a higher-order factor (poverty), three subfactors (dimensions of poverty) and three indicators for each dimension. With that in mind, we need to tell <code>lavaan</code> how our model looks like and, because <span class="math inline">\(\omega\)</span> and <span class="math inline">\(\omega_h\)</span> is easier to compute from <span class="citation">Schmid &amp; Leiman (<a href="references.html#ref-Schmid1957" role="doc-biblioref">1957</a>)</span> transformation, we will specify such type of model directly rather than a nested model. To do so, we will store the model on the object <code>MD_model</code>. We are saying something very simple. First, we are saying that the higher-order factor <em>h</em> has nine manifest variables (x1-x9). Then we say that each dimension has three outcome variables. For example, F1 has x7, x8 and x9. Then we tell <code>lavaan</code> that our factor variance are equal to zero for identification and being consistent with the <span class="citation">Schmid &amp; Leiman (<a href="references.html#ref-Schmid1957" role="doc-biblioref">1957</a>)</span> transformation.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Omega from Sem</span>
<span class="kw">library</span>(lavaan)
<span class="co"># We first specify the model</span>
MD_model &lt;-<span class="st"> &#39; h =~ +x1+x2+x3+x4+x5+x6+x7+x8+x9 </span>
<span class="st">                F1=~  + x7 + x8 + x9        </span>
<span class="st">                F2=~  + x4 + x5 + x6         </span>
<span class="st">                F3=~  + x1 + x2 + x3</span>
<span class="st">                h  ~~ 0*F1</span>
<span class="st">                h  ~~ 0*F2</span>
<span class="st">                h  ~~ 0*F3</span>
<span class="st">                F1 ~~ 0*F2</span>
<span class="st">                F2 ~~ 0*F3</span>
<span class="st">                F1 ~~ 0*F3</span>

<span class="st">&#39;</span></code></pre>
<p>Once we have specified our model, we can proceed to tell <code>lavaan</code> to estimate the model. To fit the CFA model we will use <code>sem</code> function which has been harmonised with the functions <code>cfa</code> and <code>lavaan</code>. Remember that the kind of variables we have are categorical -so we include the option <code>ordered()</code> and we will request standardised loadings with <code>std.lv=TRUE</code>. We will store the output on the object <code>fit</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">fit &lt;-<span class="st"> </span><span class="kw">sem</span>(MD_model, <span class="dt">data =</span> Rel_MD_<span class="dv">1</span>, 
           <span class="dt">ordered=</span><span class="kw">c</span>(<span class="st">&quot;x1&quot;</span>,<span class="st">&quot;x2&quot;</span>,<span class="st">&quot;x3&quot;</span>,<span class="st">&quot;x4&quot;</span>,<span class="st">&quot;x5&quot;</span>,
                     <span class="st">&quot;x6&quot;</span>,<span class="st">&quot;x7&quot;</span>,<span class="st">&quot;x8&quot;</span>,<span class="st">&quot;x9&quot;</span>),
           <span class="dt">std.lv=</span><span class="ot">TRUE</span>)
<span class="co"># The command below is to check the output (We will check this in the </span>
<span class="co">#next section and validity chapter)</span>
<span class="co">#summary(fit, fit.measures=TRUE, rsquare=TRUE, standardized=TRUE)</span></code></pre>
<p>Before showing the authomated way to estimate <span class="math inline">\(\omega\)</span> and <span class="math inline">\(\omega_h\)</span>, we will show the manual computation. There are two main parameters one needs for their computation: factor loadings from the indicators to the overall factor (<span class="math inline">\(\lambda_h\)</span>), to each dimension (<span class="math inline">\(\lambda_j\)</span>) and the error. This can be easily extracted from the fit object as follows:</p>
<pre class="sourceCode r"><code class="sourceCode r">lambdas&lt;-<span class="kw">as.data.frame</span>(fit<span class="op">@</span>Model<span class="op">@</span>GLIST<span class="op">$</span>lambda)
error&lt;-<span class="kw">colSums</span>(fit<span class="op">@</span>Model<span class="op">@</span>GLIST<span class="op">$</span>theta)</code></pre>
<p>The then the square of the sum of the loadings (<span class="math inline">\(\lambda_h\)</span>) and (<span class="math inline">\(\lambda_j\)</span>) is taken as well as the sum of the error. The we can compute both <span class="math inline">\(\omega\)</span> and <span class="math inline">\(\omega_h\)</span> using equation <a href="Chapter-3.html#eq:omega">(3.6)</a> and <a href="Chapter-3.html#eq:omegah">(3.7)</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r">Slambda_<span class="dv">2</span>&lt;-<span class="kw">sum</span>(lambdas[<span class="dv">1</span>])<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>(lambdas[<span class="dv">2</span>])<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>
<span class="st">           </span><span class="kw">sum</span>(lambdas[<span class="dv">3</span>])<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>(lambdas[<span class="dv">4</span>])<span class="op">^</span><span class="dv">2</span>
error &lt;-<span class="st"> </span><span class="kw">sum</span>(error)

omega_t &lt;-<span class="st"> </span>Slambda_<span class="dv">2</span> <span class="op">/</span><span class="st"> </span>(Slambda_<span class="dv">2</span><span class="op">+</span>error)
omega_h &lt;-<span class="st"> </span><span class="kw">sum</span>(lambdas[<span class="dv">1</span>])<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>(Slambda_<span class="dv">2</span><span class="op">+</span>error)
omegamanual&lt;-<span class="kw">c</span>(<span class="dt">omega_h=</span>omega_h,<span class="dt">omega_t=</span>omega_t)
omegamanual</code></pre>
<pre><code>##   omega_h   omega_t 
## 0.8445022 0.9707344</code></pre>
<p>Fortunately, there is an R function from the <code>psych</code> package that does this for us. Once the model has been fitted, we apply the function <code>omegaFromSem()</code> to request the estimates and store the estimates of both <span class="math inline">\(\omega\)</span> and <span class="math inline">\(\omega_h\)</span> in the <code>omegasem</code> object. The results indicate high overall reliability and high reliability after considering the multidimensional features of the scale.</p>
<pre class="sourceCode r"><code class="sourceCode r">omegasem&lt;-<span class="kw">omegaFromSem</span>(fit)
omegasem&lt;-<span class="kw">c</span>(<span class="dt">omega_h=</span>omegasem<span class="op">$</span>omega,
            <span class="dt">omega_t=</span>omegasem<span class="op">$</span>omega.tot)
omegasem</code></pre>
<pre><code>##   omega_h   omega_t 
## 0.8446990 0.9707276</code></pre>
</div>
<div id="computation-using-mplus-via-r" class="section level4">
<h4><span class="header-section-number">3.5.3.2</span> Computation using Mplus via R</h4>
<p>The R-package <code>mplusAutomation</code> is an excellent alternative to automate Mplus from within R -so you get track of your input files and do not get lost with so many windows- <span class="citation">(Hallquist &amp; Wiley, <a href="references.html#ref-Hallquist2018" role="doc-biblioref">2018</a>)</span>. We can create within R an Mplus object as follows using the function <code>mplusObject()</code>. The syntax is the standard Mplus syntax to fit a model. What we need to tell Mplus is the name of the variables, the type of variables and which variables is going to use. Then in the ANALYSIS section, we instruct Mplus to use the wlsmv estimator and four cores<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>. Then we tell Mplus that the overall factor <em>h</em> has nine outcome measures and that each dimension has three indicators. We set the variances equal to zero to be consisten with the <span class="citation">Schmid &amp; Leiman (<a href="references.html#ref-Schmid1957" role="doc-biblioref">1957</a>)</span> transformation. As with <code>lavaan</code> we will fit a bi-factor model. We will store the syntax in the object <code>test</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">test &lt;-<span class="st"> </span><span class="kw">mplusObject</span>(
<span class="dt">TITLE =</span> <span class="st">&quot;Bi-factor model CFA;&quot;</span>,
   <span class="dt">VARIABLE =</span> <span class="st">&quot;</span>
<span class="st">     NAMES = x1-x11 resources educ_yr occupation class;</span>
<span class="st">     CATEGORICAL = x1-x9;</span>
<span class="st">     USEVARIABLES = x1-x9;&quot;</span>,
   <span class="dt">ANALYSIS =</span> <span class="st">&quot;ESTIMATOR = wlsmv;</span>
<span class="st">              PROCESS = 4;&quot;</span>,

<span class="dt">MODEL =</span> <span class="st">&quot;f1 by x1-x3;</span>
<span class="st">  f2 by x4-x6;</span>
<span class="st">  f3 by x7-x9;</span>
<span class="st">  h by x1 x2 x3 x4 x4 x5 x6 x7 x8 x9;</span>
<span class="st">  F1 with F2@0;</span>
<span class="st">  F2 with F3@0;</span>
<span class="st">  F3 with F1@0;</span>
<span class="st">  h with f1@0;</span>
<span class="st">  h with f2@0;</span>
<span class="st">  h with f3@0;&quot;</span>,

<span class="dt">OUTPUT =</span> <span class="st">&quot;std stdyx;&quot;</span>)</code></pre>
<p>Now we have the model specyfication saved on the <code>test</code> object. We need know to pass this R syntax to Mplus (*.inp). The function <code>mplusModeler()</code> is going to do this for us. We tell the function that we have the object <code>test</code>, that we want an Mplus syntax file named “rel_CFA_2.inp”, and to tell Mplus to use the following data “Rel_MD_data_1_1.dat”. This function permits estimating the model directly using the option <code>run</code><a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a></p>
<pre class="sourceCode r"><code class="sourceCode r">res &lt;-<span class="st"> </span><span class="kw">mplusModeler</span>(test, <span class="dt">modelout =</span> <span class="st">&quot;rel_CFA_2.inp&quot;</span>, 
                    <span class="dt">writeData =</span> <span class="st">&quot;never&quot;</span>, <span class="dt">hashfilename =</span> <span class="ot">FALSE</span>, 
                    <span class="dt">dataout=</span><span class="st">&quot;Rel_MD_data_1_1.dat&quot;</span>, <span class="dt">run =</span> 1L)</code></pre>
<pre><code>## 
## Running model: rel_CFA_2.inp 
## System command: C:\WINDOWS\system32\cmd.exe /c cd &quot;.&quot; &amp;&amp; &quot;Mplus&quot; &quot;rel_CFA_2.inp&quot; 
## Reading model:  rel_CFA_2.out</code></pre>
<p>Once the model has been run, we can import the output using the function <code>readModels()</code>. We will explore the full output in the next chapter as for now we will focus in the estimation of <span class="math inline">\(\omega\)</span> and <span class="math inline">\(\omega_h\)</span>. The factor loadings of the Bi-factor model are stored on a R list (parameters). We request the standardised estimates as we did with <code>lavaan</code>. We can also ask for the error from the `<code>r2</code> object in the parameters list. Once we have the parameters, we can proceed as above to estimate the reliability statistics. We see that we could replicate the results from <code>lavaan</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">REL_CFA_<span class="dv">2</span>&lt;-<span class="kw">readModels</span>(<span class="dt">filefilter =</span><span class="st">&quot;rel_CFA_2&quot;</span>)</code></pre>
<pre><code>## Reading model:  C:/Proyectos Investigacion/PM Book/rel_cfa_2.out</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">lambdas&lt;-REL_CFA_<span class="dv">2</span><span class="op">$</span>parameters<span class="op">$</span>std.standardized[<span class="dv">1</span><span class="op">:</span><span class="dv">18</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>]
error&lt;-REL_CFA_<span class="dv">2</span><span class="op">$</span>parameters<span class="op">$</span>r2[<span class="dv">6</span>]

lambda_<span class="dv">2</span>&lt;-<span class="kw">sum</span>(lambdas[<span class="dv">10</span><span class="op">:</span><span class="dv">18</span>,<span class="dv">3</span>])<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>(lambdas[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>,<span class="dv">3</span>])<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>
<span class="st">          </span><span class="kw">sum</span>(lambdas[<span class="dv">4</span><span class="op">:</span><span class="dv">6</span>,<span class="dv">3</span>])<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>(lambdas[<span class="dv">7</span><span class="op">:</span><span class="dv">9</span>,<span class="dv">3</span>])<span class="op">^</span><span class="dv">2</span>
error &lt;-<span class="st"> </span><span class="kw">sum</span>(error)

omega_t &lt;-<span class="st"> </span>lambda_<span class="dv">2</span> <span class="op">/</span><span class="st"> </span>(lambda_<span class="dv">2</span><span class="op">+</span>error)
omega_h &lt;-<span class="st"> </span><span class="kw">sum</span>(lambdas[<span class="dv">10</span><span class="op">:</span><span class="dv">18</span>,<span class="dv">3</span>])<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>(lambda_<span class="dv">2</span><span class="op">+</span>error)

omega_t</code></pre>
<pre><code>## [1] 0.9707333</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">omega_h</code></pre>
<pre><code>## [1] 0.8445348</code></pre>
</div>
</div>
<div id="overall-reliability-and-population-orderings" class="section level3">
<h3><span class="header-section-number">3.5.4</span> Overall reliability and population orderings</h3>
<p>One of the predictions of measurement theory is that reliability leads to consistent population orderings, i.e. poor people will have high deprivation scores and not poor people will have low deprivation scores (see Table (<a href="Chapter-3.html#tab:relentropy">3.2</a>). We have illustrated this point using the correlation between the different deprivation scores corresponding to diverse levels of overall reliabilities. We can follow up that example by looking at the values of the latent variable for the multidimensional reliable measure (Rel_MD_1). After fitting the CFA model we just can simply use the function <code>predict()</code> to obtain the Maximum Likelihood estimates of the latent variable. Then we can merge these values with our data set. The prediction will generate four estimates for the latent variables. The overall factor (h) and the values for the three dimensions.</p>
<pre class="sourceCode r"><code class="sourceCode r">factor_scores&lt;-<span class="kw">predict</span>(fit)
Rel_MD_<span class="dv">1</span>&lt;-<span class="kw">cbind</span>(Rel_MD_<span class="dv">1</span>,factor_scores)
<span class="kw">head</span>(Rel_MD_<span class="dv">1</span>[,<span class="kw">c</span>(<span class="dv">21</span><span class="op">:</span><span class="dv">24</span>)])</code></pre>
<pre><code>##   ds_r5 ds_ur ds_ur2          h
## 1     3     2      2  0.4475885
## 2     0     0      0 -0.6781638
## 3     1     1      1 -0.2440620
## 4     2     1      1  0.2851351
## 5     1     2      2 -0.2207057
## 6     1     0      0 -0.2207057</code></pre>
<p>To contrast the values of the reliable multidimensional measure with the values of a slightly less reliable measure we will fit a new model. As in the previous example (Section @ref(#Chapter-3-expoverel)), we will replace the first two indicators x1 and x2 by x10 and x11. Both load into the first factor (f1). The estimates are stored in a different object (fit_ur) and estimate the factor scores using the <code>predict()</code> function. Finally, we inspect the values.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">## We first specify the model</span>
MD_model &lt;-<span class="st"> &#39; h =~ +x10+x11+x3+x4+x5+x6+x7+x8+x9 </span>
<span class="st">                F1=~  + x7 + x8 + x9        </span>
<span class="st">                F2=~  + x4 + x5 + x6         </span>
<span class="st">                F3=~  + x10 + x11 + x3</span>
<span class="st">                h  ~~ 0*F1</span>
<span class="st">                h  ~~ 0*F2</span>
<span class="st">                h  ~~ 0*F3</span>
<span class="st">                F1 ~~ 0*F2</span>
<span class="st">                F2 ~~ 0*F3</span>
<span class="st">                F1 ~~ 0*F3</span>

<span class="st">&#39;</span>

fit_ur &lt;-<span class="st"> </span><span class="kw">sem</span>(MD_model, <span class="dt">data =</span> Rel_MD_<span class="dv">1</span>, 
           <span class="dt">ordered=</span><span class="kw">c</span>(<span class="st">&quot;x10&quot;</span>,<span class="st">&quot;x11&quot;</span>,<span class="st">&quot;x3&quot;</span>,<span class="st">&quot;x4&quot;</span>,<span class="st">&quot;x5&quot;</span>,<span class="st">&quot;x6&quot;</span>,<span class="st">&quot;x7&quot;</span>,<span class="st">&quot;x8&quot;</span>,<span class="st">&quot;x9&quot;</span>),
           <span class="dt">std.lv=</span><span class="ot">TRUE</span>)
factor_scores_ur&lt;-<span class="kw">predict</span>(fit_ur)
<span class="kw">colnames</span>(factor_scores_ur)[<span class="dv">1</span><span class="op">:</span><span class="dv">4</span>]&lt;-<span class="kw">c</span>(<span class="st">&quot;hur&quot;</span>,<span class="st">&quot;F1ur&quot;</span>,<span class="st">&quot;F2ur&quot;</span>,<span class="st">&quot;F3ur&quot;</span>)
Rel_MD_<span class="dv">1</span>&lt;-<span class="kw">cbind</span>(Rel_MD_<span class="dv">1</span>,factor_scores_ur)
<span class="kw">head</span>(Rel_MD_<span class="dv">1</span>[,<span class="kw">c</span>(<span class="dv">25</span><span class="op">:</span><span class="dv">28</span>)])</code></pre>
<pre><code>##            F1         F2         F3         hur
## 1 -0.81293477 -0.1296229  1.2478407  0.38436469
## 2 -0.08627376 -0.1536510 -0.1720003 -0.59656764
## 3 -0.28822588  0.5290560 -0.3986557 -0.10512455
## 4  0.13806885 -0.7559100  0.7442695 -0.05228111
## 5 -0.30252106 -0.3910445  0.4514504 -0.50856087
## 6 -0.30252106 -0.3910445  0.4514504 -0.59656764</code></pre>
<p>To assess the consistency of both multidimensional scales we will plot the latent factor values by the deprivation score. Figure <a href="Chapter-3.html#fig:fsdesrel">3.2</a> shows that the factor scores are very similar within each deprivation group. For each deprivation score we find very different factor scores, indicating that the deprivation scores is a good measure to rank and split the population according to the severity of deprivation. In contrast, figure <a href="Chapter-3.html#fig:fsdesunrel">3.3</a> show that although there is relationship between the deprivation score and factor scores, this relationship is more noisy. Not only there is much more variability within each deprivation group but also there is some overlap. That means that if we use some cut off to split the poor from the not poor based on a deprivation score, we will be more likely to confound both groups. In this case, the mixing of groups is not that dramatic as the scale is still somewhat reliable, but it could be very noisy for less reliable scales.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(ggplot2)
g &lt;-<span class="st"> </span><span class="kw">ggplot</span>(Rel_MD_<span class="dv">1</span>, <span class="kw">aes</span>(<span class="kw">as.factor</span>(ds), h))
g <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>(<span class="dt">varwidth=</span>T) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">x=</span><span class="st">&quot;Deprivation score. Reliable&quot;</span>,
         <span class="dt">y=</span><span class="st">&quot;Factor score (Latent variable)&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</code></pre>
<div class="figure"><span id="fig:fsdesrel"></span>
<img src="PM_Book_files/figure-html/fsdesrel-1.png" alt="Relationship between the deprivation score (x1-x9) and the latent variable score. We appreciate the narrowness of the box plots, indicating good group separation." width="672" />
<p class="caption">
Figure 3.2: Relationship between the deprivation score (x1-x9) and the latent variable score. We appreciate the narrowness of the box plots, indicating good group separation.
</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r">g &lt;-<span class="st"> </span><span class="kw">ggplot</span>(Rel_MD_<span class="dv">1</span>, <span class="kw">aes</span>(<span class="kw">as.factor</span>(ds_ur), hur))
g <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>(<span class="dt">varwidth=</span>T) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">x=</span><span class="st">&quot;Deprivation score. Unreliable&quot;</span>,
         <span class="dt">y=</span><span class="st">&quot;Factor score (Latent variable)&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</code></pre>
<div class="figure"><span id="fig:fsdesunrel"></span>
<img src="PM_Book_files/figure-html/fsdesunrel-1.png" alt="Relationship between the deprivation score (x10, x11 and x3-x9) and the latent variable score. There is more variability in this case indicating poor group separation." width="672" />
<p class="caption">
Figure 3.3: Relationship between the deprivation score (x10, x11 and x3-x9) and the latent variable score. There is more variability in this case indicating poor group separation.
</p>
</div>
</div>
<div id="item-level-reliability" class="section level3">
<h3><span class="header-section-number">3.5.5</span> Item-level reliability</h3>
<div id="estimation-with-r" class="section level4">
<h4><span class="header-section-number">3.5.5.1</span> Estimation with R</h4>
<p>Overall reliability is an excellent summary of the quality of an index in that it tells the homogeneity of our scale and its capacity to produce consistent population rankings. In section @ref(#relestimation) we showed that including some uncorrelated items lead to a reduction of reliability and that this has negative implication for consistency across measurements. This section focuses on item reliability, i.e. how specific items contribute positively or negatively to reliability.</p>
<p>Section <a href="Chapter-3.html#itemlevelrel">3.4</a> reviewed Item Response Theory (IRT), which is a theory of the properties of indicators by putting forward the concepts of discrimination and severity. The standard IRT modelling assumes that scales are unidimensional in that indicators are manifest of a latent trait. However, in parallel to the development of CFA, IRT modelling has incorporated multidimensional models. However, as long as a scale is homogeneous, the bias from a multidimensional IRT and the unidimensional one should not dramatically change our conclusions about the reliability of the items.</p>
<p>To illustrate IRT modelling, we will work with the same data set, which we know that results in a highly homogeneous scale. We will use the data “Rel_MD_1” and the R-package <code>ltm</code> which fits different kinds of IRT models. The <code>ltm()</code> function fits one, two and three-parameter IRT models. Below we fit a two-parameter IRT model simply by adding the <code>z1</code> option so we allow the model to have different slopes, i.e. Two-parameter IRT model. The output shows the difficulty and discrimination coefficients. The difficulty represents the severity of the deprivation on the latent trait. For example, item x1 is less severe than item x3. The second column <code>Dscrmn</code> displays the values of the discrimination parameters. All the items have values <span class="math inline">\(&gt;.9\)</span> which is above the suggested threshold by <span class="citation">Guio et al. (<a href="references.html#ref-Guio2016" role="doc-biblioref">2016</a>)</span> and <span class="citation">Nájera (<a href="references.html#ref-Najera2018" role="doc-biblioref">2018</a>)</span>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ltm)
rel_irt&lt;-<span class="kw">ltm</span>(Rel_MD_<span class="dv">1</span>[,<span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">9</span>)] <span class="op">~</span><span class="st"> </span>z1)
rel_irt</code></pre>
<pre><code>## 
## Call:
## ltm(formula = Rel_MD_1[, c(1:9)] ~ z1)
## 
## Coefficients:
##     Dffclt  Dscrmn
## x1   0.023   2.290
## x2   0.702   2.183
## x3   1.258   2.198
## x4   0.053   2.306
## x5   0.698   2.368
## x6   1.297   2.154
## x7   0.160   2.541
## x8   0.802   2.547
## x9   1.236   2.477
## 
## Log.Lik: -20132.92</code></pre>
<p>Before checking the estimation with Mplus, we will check what will happen if we include our unreliable items. Items x1 and x2 are replaced by items V1 and V2. As expected, the discrimination values are unacceptably low as well as the severity values which are (<span class="math inline">\(\geq3\)</span>) standard deviations.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(Rel_MD_<span class="dv">1</span>[,<span class="kw">c</span>(<span class="dv">3</span><span class="op">:</span><span class="dv">11</span>)])</code></pre>
<pre><code>##   x3 x4 x5 x6 x7 x8 x9 x10 x11
## 1  1  1  0  0  0  0  0   0   0
## 2  0  0  0  0  0  0  0   0   0
## 3  0  1  0  0  0  0  0   0   0
## 4  0  0  0  0  1  0  0   0   0
## 5  0  0  0  0  0  0  0   1   1
## 6  0  0  0  0  0  0  0   0   0</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">rel_irt_<span class="dv">2</span>&lt;-<span class="kw">ltm</span>(Rel_MD_<span class="dv">1</span>[,<span class="kw">c</span>(<span class="dv">3</span><span class="op">:</span><span class="dv">11</span>)] <span class="op">~</span><span class="st"> </span>z1)
rel_irt_<span class="dv">2</span></code></pre>
<pre><code>## 
## Call:
## ltm(formula = Rel_MD_1[, c(3:11)] ~ z1)
## 
## Coefficients:
##      Dffclt  Dscrmn
## x3    1.426   1.651
## x4    0.053   2.371
## x5    0.689   2.488
## x6    1.279   2.245
## x7    0.157   2.817
## x8    0.780   2.840
## x9    1.193   2.804
## x10   5.142   0.133
## x11   4.882   0.135
## 
## Log.Lik: -21740.2</code></pre>
</div>
<div id="mplus-estimation-within-r" class="section level4">
<h4><span class="header-section-number">3.5.5.2</span> Mplus estimation within R</h4>
<p>Similarly we can fit the model using items (x1-x9) in Mplus using the package “mplusAutomation” by creating an object with <code>mplusObject()</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">test &lt;-<span class="st"> </span><span class="kw">mplusObject</span>(
<span class="dt">TITLE =</span> <span class="st">&quot;IRT model;&quot;</span>,
   <span class="dt">VARIABLE =</span> <span class="st">&quot;</span>
<span class="st">     NAMES = x1-x9 resources educ_yr occupation hh_size class;</span>
<span class="st">     CATEGORICAL = x1-x9;</span>
<span class="st">     USEVARIABLES = x1-x9;&quot;</span>,
   <span class="dt">ANALYSIS =</span> <span class="st">&quot;ESTIMATOR = ml;</span>
<span class="st">              PROCESS = 4;&quot;</span>,

<span class="dt">MODEL =</span> <span class="st">&quot;h by x1* x2-x9;</span>
<span class="st">         h@1;&quot;</span>)</code></pre>
<p>Then the model is fitted using <code>mplusModeler()</code>. We will name our Mplus script as “rel_IRT_1.inp” and we will be using the same data as before (“Rel_MD_data_1_1.dat”) and we request Mplus to run the model directly from the script with (<code>run</code>).</p>
<pre class="sourceCode r"><code class="sourceCode r">res &lt;-<span class="st"> </span><span class="kw">mplusModeler</span>(test, <span class="dt">modelout =</span> <span class="st">&quot;rel_IRT_1.inp&quot;</span>, 
                    <span class="dt">writeData =</span> <span class="st">&quot;never&quot;</span>, <span class="dt">hashfilename =</span> <span class="ot">FALSE</span>, 
                    <span class="dt">dataout=</span><span class="st">&quot;Rel_MD_data_1_1.dat&quot;</span>, <span class="dt">run =</span> 1L)</code></pre>
<p>Now we read the result of our model with <code>readModels()</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">REL_IRT_<span class="dv">1</span>&lt;-<span class="kw">readModels</span>(<span class="dt">filefilter =</span><span class="st">&quot;rel_IRT_1&quot;</span>)</code></pre>
<p>The <code>readModels()</code> does an excellent job in extracting and ordering the Mplus output. It puts all the relevant result in lists. We can see that the Mplus estimates are very similar to those obtained from the <code>ltm</code> package.</p>
<pre class="sourceCode r"><code class="sourceCode r">rel_irt&lt;-REL_IRT_<span class="dv">1</span><span class="op">$</span>parameters<span class="op">$</span>irt.parameterization
rel_irt&lt;-rel_irt[<span class="dv">1</span><span class="op">:</span><span class="dv">18</span>,]
rel_irt&lt;-<span class="kw">data.frame</span>(<span class="dt">a=</span>rel_irt<span class="op">$</span>est[<span class="dv">1</span><span class="op">:</span><span class="dv">9</span>],<span class="dt">b=</span>rel_irt<span class="op">$</span>est[<span class="dv">10</span><span class="op">:</span><span class="dv">18</span>])
rel_irt</code></pre>
<pre><code>##       a     b
## 1 2.290 0.024
## 2 2.192 0.700
## 3 2.207 1.254
## 4 2.312 0.054
## 5 2.383 0.696
## 6 2.172 1.291
## 7 2.548 0.161
## 8 2.561 0.800
## 9 2.498 1.231</code></pre>
</div>
</div>
</div>
<div id="multidimensional-item-reliability-evaluation" class="section level2">
<h2><span class="header-section-number">3.6</span> Multidimensional item-reliability evaluation</h2>
<p>A multidimensional IRT model is just a CFA model with categorical indicators. One way to assess the item-level reliability is by looking at the loadings from a CFA model. We can fit a higher-order factor model (equivalent to the bi-factor model above) to assess the value of the loadings and and look at the <span class="math inline">\(R^2\)</span> values of each indicator (which is just <span class="math inline">\(\lambda{hj}^2\)</span>). <span class="math inline">\(R^2\leq.25\)</span> are equivalent to <span class="math inline">\(\lambda{hj}^2\leq.5\)</span>, which are often used as cut offs of unacceptably low loadings. We see that all these items are highly reliable not only with regard the higher order factor but also in terms of each dimension, measured by each factor loading.</p>
<pre class="sourceCode r"><code class="sourceCode r"> MD_model &lt;-<span class="st"> &#39; f1  =~ x1 + x2 + x3</span>
<span class="st">              f2 =~ x4 + x5 + x6</span>
<span class="st">              f3   =~ x7 + x8 + x9</span>
<span class="st">                h =~ f1 + f2 + f3</span>
<span class="st"> &#39;</span>

fit &lt;-<span class="st"> </span><span class="kw">sem</span>(MD_model, <span class="dt">data =</span> Rel_MD_<span class="dv">1</span>,
           <span class="dt">ordered=</span><span class="kw">c</span>(<span class="st">&quot;x1&quot;</span>,<span class="st">&quot;x2&quot;</span>,<span class="st">&quot;x3&quot;</span>,<span class="st">&quot;x4&quot;</span>,<span class="st">&quot;x5&quot;</span>,
                     <span class="st">&quot;x6&quot;</span>,<span class="st">&quot;x7&quot;</span>,<span class="st">&quot;x8&quot;</span>,<span class="st">&quot;x9&quot;</span>))
<span class="kw">inspect</span>(fit,<span class="dt">what=</span><span class="st">&quot;std&quot;</span>)<span class="op">$</span>lambda</code></pre>
<pre><code>##       f1    f2    f3 h
## x1 0.924 0.000 0.000 0
## x2 0.888 0.000 0.000 0
## x3 0.873 0.000 0.000 0
## x4 0.000 0.929 0.000 0
## x5 0.000 0.917 0.000 0
## x6 0.000 0.866 0.000 0
## x7 0.000 0.000 0.947 0
## x8 0.000 0.000 0.916 0
## x9 0.000 0.000 0.894 0</code></pre>
<div id="item-reliability-and-monotonicity" class="section level3">
<h3><span class="header-section-number">3.6.1</span> Item-reliability and monotonicity</h3>
<p>Low loadings are an indication that the indicator is not a manifest variable of the underlying construct. That is, that changes in poverty do not mirror changes in deprivation. Section <a href="Chapter-3.html#itemlevelrel">3.4</a> suggested that there is a relationship between item-reliability and the monotonicity axiom. <span class="citation">Nájera (<a href="references.html#ref-NajeraForthcoming" role="doc-biblioref">n.d.</a>)</span> shows that indeed low loadings approximately <span class="math inline">\(\leq.5\)</span> lead to violations of the strong monotonicity axiom, i.e. a reduction in poverty does not reflect an improvement in the achievement matrix. Weak monotonicity is violated when an improvement in poverty results in an increase of deprivation, this would happen when the factor loadings are negative, for example.</p>
<p>We will fit a higher order model using again the unreliable items (x10 and x11) instead of x1 and x2. Of course, it is possible to use either the loadings of the <span class="math inline">\(R^2\)</span> values (these can be obtained with the <code>summary()</code> function. We see again, as in the IRT analysis that both items have unacceptably low values. These items should be dropped from the scale as it inclusion introduces noise to our measure. That would imply dropping the first dimension in the absence of alternative indicators.</p>
<pre class="sourceCode r"><code class="sourceCode r"> MD_model &lt;-<span class="st"> &#39; f1  =~ x10 + x11 + x3</span>
<span class="st">              f2 =~ x4 + x5 + x6</span>
<span class="st">              f3   =~ x7 + x8 + x9</span>
<span class="st">                h =~ f1 + f2 + f3</span>
<span class="st"> &#39;</span>

fit &lt;-<span class="st"> </span><span class="kw">sem</span>(MD_model, <span class="dt">data =</span> Rel_MD_<span class="dv">1</span>,
           <span class="dt">ordered=</span><span class="kw">c</span>(<span class="st">&quot;x10&quot;</span>,<span class="st">&quot;x11&quot;</span>,<span class="st">&quot;x3&quot;</span>,<span class="st">&quot;x4&quot;</span>,<span class="st">&quot;x5&quot;</span>,
                      <span class="st">&quot;x6&quot;</span>,<span class="st">&quot;x7&quot;</span>,<span class="st">&quot;x8&quot;</span>,<span class="st">&quot;x9&quot;</span>))</code></pre>
<pre><code>## Warning in lav_object_post_check(object): lavaan WARNING: some estimated ov
## variances are negative</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">inspect</span>(fit,<span class="dt">what=</span><span class="st">&quot;std&quot;</span>)<span class="op">$</span>lambda</code></pre>
<pre><code>##        f1    f2    f3 h
## x10 0.114 0.000 0.000 0
## x11 0.116 0.000 0.000 0
## x3  1.036 0.000 0.000 0
## x4  0.000 0.924 0.000 0
## x5  0.000 0.920 0.000 0
## x6  0.000 0.868 0.000 0
## x7  0.000 0.000 0.947 0
## x8  0.000 0.000 0.914 0
## x9  0.000 0.000 0.898 0</code></pre>
</div>
</div>
<div id="real-data-example" class="section level2">
<h2><span class="header-section-number">3.7</span> Real data example</h2>
<p>We will use the Mexican data set “Mex_pobreza_14.dat”. This data set contains a subset of the deprivation indicators utilised to measure multidimensional poverty in Mexico. The official measure has two domains: income and social rights. The social rights domain has five dimensions: essential services, housing, food deprivation, social security and education. Some of this dimensions are measured with few indicators, like education and social security. This poses limitations to fit an identified model. Hence, we will use a reduced version of the model comprising three dimensions: essential services, housing and food deprivation.</p>
<p>The Mexican poverty data comes from a nationally representative complex survey. We will use the package “survey” <span class="citation">(Lumley, <a href="references.html#ref-Lumley2016" role="doc-biblioref">2016</a>)</span>. This is a comprehensive R-package to analyse survey data. We strongly advice readers to check <span class="citation">Lumley (<a href="references.html#ref-Lumley2011" role="doc-biblioref">2011</a>)</span> book on complex surveys to get a depth insight on complex sampling and the use of Lumley’s excellent package. To produce design deprivation rates estimates for each of the 14 items we need to specify few things. First, we need to identify the sampling weights and the primary sampling units (PSU). The <code>options(scipen=999, survey.lonely.psu="adjust")</code> instruction is to prevent errors as sometimes there is one household per PSU. Once we have set up the sampling design we can estimate the deprivation rates with the <code>svymean()</code> function -we have rounded the percentages for simplicity; never try to be too accurate with survey data-. We can see than deprivation in the housing dimension items is rather low. Essential services present higher deprivation rates but electricity is very low. We see that the food deprivation items have the higher rates on average.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(haven)
Mex_D&lt;-<span class="kw">read_dta</span>(<span class="st">&quot;pobreza_14.dta&quot;</span>)

cols &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;icv_muros&quot;</span>, <span class="st">&quot;icv_techos&quot;</span>, <span class="st">&quot;icv_pisos&quot;</span>, <span class="st">&quot;icv_hac&quot;</span>,
          <span class="st">&quot;isb_agua&quot;</span>,<span class="st">&quot;isb_dren&quot;</span>, <span class="st">&quot;isb_luz&quot;</span>, <span class="st">&quot;isb_combus&quot;</span>,
          <span class="st">&quot;ic_sbv&quot;</span>, <span class="st">&quot;ia_1ad&quot;</span>, <span class="st">&quot;ia_2ad&quot;</span>, <span class="st">&quot;ia_3ad&quot;</span>, <span class="st">&quot;ia_4ad&quot;</span>, 
          <span class="st">&quot;ia_5ad&quot;</span>,  <span class="st">&quot;ia_6ad&quot;</span>)

<span class="kw">library</span>(survey)
<span class="kw">options</span>(<span class="dt">scipen=</span><span class="dv">999</span>, <span class="dt">survey.lonely.psu=</span><span class="st">&quot;adjust&quot;</span>)
des &lt;-<span class="st"> </span><span class="kw">svydesign</span>(<span class="dt">data=</span>Mex_D, <span class="dt">id=</span><span class="op">~</span><span class="dv">1</span>, <span class="dt">CLUSTER=</span><span class="op">~</span>psu, <span class="dt">weights=</span><span class="op">~</span>weight)
propr &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">svymean</span>(Mex_D[, cols],des,<span class="dt">na.rm=</span>T))
propr &lt;-<span class="st"> </span><span class="kw">round</span>(propr<span class="op">*</span><span class="dv">100</span>,<span class="dv">1</span>)
propr</code></pre>
<pre><code>##            mean  SE
## icv_muros   1.7 0.1
## icv_techos  1.6 0.1
## icv_pisos   3.0 0.1
## icv_hac     5.6 0.1
## isb_agua    7.7 0.1
## isb_dren    7.5 0.1
## isb_luz     0.8 0.0
## isb_combus 12.0 0.2
## ic_sbv     19.6 0.2
## ia_1ad     33.3 0.3
## ia_2ad     15.9 0.2
## ia_3ad     24.9 0.2
## ia_4ad     14.0 0.2
## ia_5ad     16.4 0.2
## ia_6ad     12.3 0.2</code></pre>
<div id="overall-reliability-1" class="section level3">
<h3><span class="header-section-number">3.7.1</span> Overall reliability</h3>
<p>Now the we are familiarised with the 14 deprivation indicators we can proceed to estimate the reliability statistics. We will fit the model in Mplus as we will incorporate the survey design in the estimation of the parameters -it is possible to do so with the <code>lavaan.survey()</code> too-. We first create our Mplus script (rel_CFA_mex.inp) to fit the bi-factor model. Following the theoretical model for this data, the model has three dimensions (housing (f1), essential services (f2) and food deprivation (f3)) and one higher-order factor (h). Once the model has been fitted we will store the output in the object called <code>REL\_CFA\_mex</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">test &lt;-<span class="st"> </span><span class="kw">mplusObject</span>(
<span class="dt">TITLE =</span> <span class="st">&quot;Bi-factor model CFA;&quot;</span>,
   <span class="dt">VARIABLE =</span> <span class="st">&quot;</span>
<span class="st">     NAMES = proyecto folioviv foliohog icv_muros icv_techos </span>
<span class="st">             icv_pisos icv_hac isb_agua isb_dren isb_luz isb_combus</span>
<span class="st">             ic_sbv ia_1ad ia_2ad ia_3ad ia_4ad ia_5ad ia_6ad</span>
<span class="st">             ia_7men ia_8men ia_9men ia_10men ia_11men ia_12men </span>
<span class="st">             tv_dep radio_dep fridge_dep</span>
<span class="st">             washingmach_dep compu_dep inter_dep psu weight</span>
<span class="st">             rururb tot_integ durables educ_hh; </span>
<span class="st">MISSING=.;</span>
<span class="st">     CATEGORICAL = icv_muros icv_techos icv_pisos icv_hac isb_agua</span>
<span class="st">                   isb_dren isb_luz isb_combus  ia_1ad </span>
<span class="st">                   ia_2ad ia_3ad ia_4ad ia_5ad ia_6ad;</span>
<span class="st">     USEVARIABLES = icv_muros icv_techos icv_pisos icv_hac isb_agua</span>
<span class="st">                   isb_dren isb_luz isb_combus  ia_1ad </span>
<span class="st">                   ia_2ad ia_3ad ia_4ad ia_5ad ia_6ad;</span>

<span class="st">WEIGHT=weight;</span>
<span class="st">cluster = psu;&quot;</span>,

   <span class="dt">ANALYSIS =</span> <span class="st">&quot;TYPE = complex;</span>

<span class="st">ESTIMATOR = wlsmv;</span>
<span class="st">PROCESS = 4;&quot;</span>,

<span class="dt">MODEL =</span> <span class="st">&quot;f1 by icv_muros icv_techos icv_pisos icv_hac;</span>
<span class="st">  f2 by isb_agua</span>
<span class="st">        isb_dren isb_luz isb_combus;</span>
<span class="st">  f3 by ia_1ad ia_2ad ia_3ad ia_4ad ia_5ad ia_6ad;</span>
<span class="st">  h  by icv_muros icv_techos icv_pisos icv_hac isb_agua</span>
<span class="st">        isb_dren isb_luz isb_combus ia_1ad ia_2ad </span>
<span class="st">        ia_3ad ia_4ad ia_5ad ia_6ad;</span>
<span class="st">  F1 with F2@0;</span>
<span class="st">  F2 with F3@0;</span>
<span class="st">  F3 with F1@0;</span>
<span class="st">  h with f1@0;</span>
<span class="st">  h with f2@0;</span>
<span class="st">  h with f3@0;&quot;</span>,

<span class="dt">OUTPUT =</span> <span class="st">&quot;std stdyx;&quot;</span>)

<span class="kw">mplusModeler</span>(test, <span class="dt">modelout =</span> <span class="st">&quot;rel_CFA_mex.inp&quot;</span>, 
                    <span class="dt">writeData =</span> <span class="st">&quot;never&quot;</span>, <span class="dt">hashfilename =</span> <span class="ot">FALSE</span>, 
                    <span class="dt">dataout=</span><span class="st">&quot;Mex_pobreza_14.dat&quot;</span>, <span class="dt">run =</span> 1L)
REL_CFA_mex&lt;-<span class="kw">readModels</span>(<span class="st">&quot;rel_CFA_mex.out&quot;</span>)</code></pre>
<p>We then can estimate the overall reliability statistics; both <span class="math inline">\(\omega\)</span> and <span class="math inline">\(\omega_h\)</span><a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a>. The reliability of our measure is very high under both statistics and both are above the recommended thresholds <span class="citation">(Nájera, <a href="references.html#ref-Najera2018" role="doc-biblioref">2018</a>)</span>. To estimate the reliability measures we will use the same approach we followed in the previous section. First, we will obtain the factor loadings (f’s and h) and the errors for each indicator. Then we will take the square of the sum of the lambdas (f1, f2, f3 and h) and the error sum. <span class="math inline">\(\omega\)</span> and <span class="math inline">\(\omega_h\)</span> then can be calculated using formulas from equations <a href="Chapter-3.html#eq:omega">(3.6)</a> and <a href="Chapter-3.html#eq:omegah">(3.7)</a>.</p>
<p>The values of both <span class="math inline">\(\omega\)</span> and <span class="math inline">\(\omega_h\)</span> are high .97 and .81, respectively. These figures suggest that this multidimensional scale is homogeneous but has multidimensional features (<span class="math inline">\(\omega_h&lt;\omega\)</span>).</p>
<pre class="sourceCode r"><code class="sourceCode r">lambdas&lt;-REL_CFA_mex<span class="op">$</span>parameters<span class="op">$</span>std.standardized[<span class="dv">1</span><span class="op">:</span><span class="dv">28</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>]
error&lt;-REL_CFA_mex<span class="op">$</span>parameters<span class="op">$</span>r2[<span class="dv">6</span>]

lambda_<span class="dv">2</span>&lt;-<span class="kw">sum</span>(lambdas[<span class="dv">10</span><span class="op">:</span><span class="dv">28</span>,<span class="dv">3</span>])<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>(lambdas[<span class="dv">1</span><span class="op">:</span><span class="dv">4</span>,<span class="dv">3</span>])<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>
<span class="st">          </span><span class="kw">sum</span>(lambdas[<span class="dv">5</span><span class="op">:</span><span class="dv">8</span>,<span class="dv">3</span>])<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>(lambdas[<span class="dv">9</span><span class="op">:</span><span class="dv">14</span>,<span class="dv">3</span>])<span class="op">^</span><span class="dv">2</span>
error &lt;-<span class="st"> </span><span class="kw">sum</span>(error)

omega_t &lt;-<span class="st"> </span>lambda_<span class="dv">2</span> <span class="op">/</span><span class="st"> </span>(lambda_<span class="dv">2</span><span class="op">+</span>error)
omega_h &lt;-<span class="st"> </span><span class="kw">sum</span>(lambdas[<span class="dv">10</span><span class="op">:</span><span class="dv">28</span>,<span class="dv">3</span>])<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>(lambda_<span class="dv">2</span><span class="op">+</span>error)

omega_t</code></pre>
<pre><code>## [1] 0.9730641</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">omega_h</code></pre>
<pre><code>## [1] 0.8058398</code></pre>
</div>
<div id="item-level-reliability-1" class="section level3">
<h3><span class="header-section-number">3.7.2</span> Item-level reliability</h3>
<p>Once we have assessed the overall reliability of the Mexican index, we can assess item-reliability by fitting a higher-order factor model and checking the value of the factor loadings. We just simply need to rewrite our model (rel_CFA_mex2.inp) to represent a structure where the dimensions load into the higher order factor (i.e. we will not fit a bi-factor model but a hierarchical factor model). This is simply done by specifying that the higher-order factor <em>h</em> is measured by the three dimensions (f1, f2 and f3) and each dimension has several indicators.</p>
<pre class="sourceCode r"><code class="sourceCode r">test &lt;-<span class="st"> </span><span class="kw">mplusObject</span>(
<span class="dt">TITLE =</span> <span class="st">&quot;CFA higher order model CFA;&quot;</span>,
   <span class="dt">VARIABLE =</span> <span class="st">&quot;</span>
<span class="st">     NAMES = proyecto folioviv foliohog icv_muros icv_techos </span>
<span class="st">             icv_pisos icv_hac isb_agua isb_dren isb_luz isb_combus</span>
<span class="st">             ic_sbv ia_1ad ia_2ad ia_3ad ia_4ad ia_5ad ia_6ad</span>
<span class="st">             ia_7men ia_8men ia_9men ia_10men ia_11men ia_12men </span>
<span class="st">             tv_dep radio_dep fridge_dep</span>
<span class="st">             washingmach_dep compu_dep inter_dep psu weight</span>
<span class="st">            rururb tot_integ; </span>
<span class="st">MISSING=.;</span>
<span class="st">     CATEGORICAL = icv_muros icv_techos icv_pisos icv_hac isb_agua</span>
<span class="st">                   isb_dren isb_luz isb_combus  ia_1ad </span>
<span class="st">                   ia_2ad ia_3ad ia_4ad ia_5ad ia_6ad;</span>
<span class="st">     USEVARIABLES = icv_muros icv_techos icv_pisos icv_hac isb_agua</span>
<span class="st">                   isb_dren isb_luz isb_combus  ia_1ad </span>
<span class="st">                   ia_2ad ia_3ad ia_4ad ia_5ad ia_6ad;</span>

<span class="st">WEIGHT=weight;</span>
<span class="st">cluster = psu;&quot;</span>,

   <span class="dt">ANALYSIS =</span> <span class="st">&quot;TYPE = complex;</span>

<span class="st">ESTIMATOR = wlsmv;</span>
<span class="st">PROCESS = 4;&quot;</span>,

<span class="dt">MODEL =</span> <span class="st">&quot;f1 by icv_muros icv_techos icv_pisos icv_hac;</span>
<span class="st">  f2 by isb_agua</span>
<span class="st">        isb_dren isb_luz isb_combus;</span>
<span class="st">  f3 by ia_1ad ia_2ad ia_3ad ia_4ad ia_5ad ia_6ad;</span>
<span class="st">  h by f1 f2 f3;&quot;</span>,

<span class="dt">OUTPUT =</span> <span class="st">&quot;std stdyx;&quot;</span>)

<span class="kw">mplusModeler</span>(test, <span class="dt">modelout =</span> <span class="st">&quot;rel_CFA_mex2.inp&quot;</span>, 
                    <span class="dt">writeData =</span> <span class="st">&quot;never&quot;</span>, <span class="dt">hashfilename =</span> <span class="ot">FALSE</span>, 
                    <span class="dt">dataout=</span><span class="st">&quot;Mex_pobreza_14.dat&quot;</span>, <span class="dt">run =</span> 1L)</code></pre>
<p>We can request the standardised factor loadings and inspect its values using the <code>readModels()</code> function. To facilitate our interpretation we can plot the standardised loadings (Figure <a href="Chapter-3.html#fig:lamdamex">3.4</a>. We see that all the indicators have very high loadings and above the suggested threshold (<span class="math inline">\(\lambda_ij&gt;.5\)</span>). That means that these indicators discriminate well and are reliable manifests of each dimension. We see, nonetheless, that the indicators of the housing dimension tend to have low values. This could be an indication that these indicators are losing discriminatory power due to changes in living standards and that the Mexican measure might need some updating.</p>
<pre class="sourceCode r"><code class="sourceCode r">REL_CFA_mex2&lt;-<span class="kw">readModels</span>(<span class="st">&quot;rel_CFA_mex2.out&quot;</span>)
modelParams&lt;-<span class="st"> </span>REL_CFA_mex2<span class="op">$</span>parameters<span class="op">$</span>std.standardized[<span class="dv">1</span><span class="op">:</span><span class="dv">14</span>,]
modelParams &lt;-<span class="st"> </span><span class="kw">subset</span>(modelParams, <span class="dt">select=</span><span class="kw">c</span>(<span class="st">&quot;paramHeader&quot;</span>, <span class="st">&quot;param&quot;</span>, <span class="st">&quot;est&quot;</span>, <span class="st">&quot;se&quot;</span>))</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
limits &lt;-<span class="st"> </span><span class="kw">aes</span>(<span class="dt">ymax =</span> est <span class="op">+</span><span class="st"> </span>se, <span class="dt">ymin=</span>est <span class="op">-</span><span class="st"> </span>se)
 <span class="kw">ggplot</span>(modelParams, <span class="kw">aes</span>(<span class="dt">x=</span>param, <span class="dt">y=</span>est)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_pointrange</span>(limits) <span class="op">+</span><span class="kw">scale_x_discrete</span>(<span class="st">&quot;&quot;</span>) <span class="op">+</span>
<span class="st">   </span><span class="kw">geom_hline</span>(<span class="dt">yintercept=</span><span class="dv">0</span>, <span class="dt">color=</span><span class="st">&quot;grey50&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>() <span class="op">+</span><span class="kw">ylab</span>(<span class="st">&quot;Std Loading&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">coord_flip</span>()</code></pre>
<div class="figure"><span id="fig:lamdamex"></span>
<img src="PM_Book_files/figure-html/lamdamex-1.png" alt="This plot shows the standardised values of the loadings for the 14 items." width="672" />
<p class="caption">
Figure 3.4: This plot shows the standardised values of the loadings for the 14 items.
</p>
</div>
<p>#Final comments</p>
<p>We have reviewed the theory, implementation and both positive and negative implications for measurement of reliability. In social sciences, we tend to work with concepts that are unlikely to be captured by a single variable. Instead, we work on an indirect way. We believe that our concepts produce certain manifestations and we use these outcomes as means to measure our constructs. This process could have very high or very low uncertainty and we would like to reduce it as much as we can. Reliability is a key principle that helps researchers to assess the extent to which they can distinguish signal from noise. In doing so, researchers are also more likely to know whether a set of indicators helps them to produce a ranking of the population. In the case of poverty, from very severe to the mild forms of deprivation.</p>
<p>The assessment of reliability involves acknowledging that in multidimensional poverty measurement we must raise a number of assumptions. Testing reliability help us to examine the extent to which our prejudices introduce noise and to detect which components of our scales need to be reworked.</p>
<p>The presumed nature of poverty (multidimensionality) demands using appropriate methods for its scrutiny. We have put forward <span class="math inline">\(\omega\)</span> and <span class="math inline">\(\omega_h\)</span> as the two most adequate statistics to estimate reliability for multidimensional scales. At this point, we have shown that a reliable measure will result in adequate population rankings, but this is not enough. So far, we know whether our indicators produce consistent results but we know little about whether the indicators in question are outcomes of poverty. In other words, we believe that the latent variable is poverty, but we have not checked whether that is the case. The next chapter concerns with the question of hitting the target, i.e. measuring what we want to measure.</p>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="4">
<li id="fn4"><p>We say latent because at this point we are thinking in terms of reliability and we have not proved that the scale measures living standards and poverty. The Chapter on Validity explains this difference<a href="Chapter-3.html#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p>In Chapter 1 we underlined the fact that we cannot claim to observe poverty directly as it is an invention of the human mind but we could claim that our theory of poverty tells us what kind of manifestations (in form of deprivation) will inform us about people’s low living standards<a href="Chapter-3.html#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p>Interestingly enough, this is a desirable property in Sen’s Axiomatic approach in the form of the monotonicity axiom <span class="citation">Nájera (<a href="references.html#ref-NajeraForthcoming" role="doc-biblioref">n.d.</a>)</span>, see <a href="Chapter-3.html#itemlevelrel">3.4</a><a href="Chapter-3.html#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p>If the scale is badly constructed reliability could be negative using some statistics like <span class="math inline">\(\alpha\)</span><a href="Chapter-3.html#fnref7" class="footnote-back">↩</a></p></li>
<li id="fn8"><p>The wlsmv estimator uses robust Weighted Least Squares to run the CFA. This estimator is a good approximation, relative to Maximum Likelihood (ML), that is less computationally intensive and feasible when having several factor, we strongly recommend to check the Mplus documentation and <span class="citation">Brown (<a href="references.html#ref-Brown2006" role="doc-biblioref">2006</a>)</span> excellent book for further insights<a href="Chapter-3.html#fnref8" class="footnote-back">↩</a></p></li>
<li id="fn9"><p>The reader will appreciate that the file “rel_CFA_2.inp” can be opened in Mplus.<a href="Chapter-3.html#fnref9" class="footnote-back">↩</a></p></li>
<li id="fn10"><p>Prior the estimation of the reliability statistics is vital to inspect the fit of the model as a poor model will not be useful to estimate omega. We will discuss in the next chapter (Validity) the meaning of these statistics. At this point we will focus on the fact that a poor model fit invariably leads to poor estimates of reliability. There is no point in estimating reliability of a scale that makes no sense at all. To assess the fit of the model we look at four statistics: <span class="math inline">\(\chi^2\)</span>, TLI, CFI and RMSEA. For this model the relative statistics of fit look fine and we have some certainties about the model we fit.<a href="Chapter-3.html#fnref10" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="Chapter-2.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="Chapter-4.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "readable",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
