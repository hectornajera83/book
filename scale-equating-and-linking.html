<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Scale equating and linking | Multidimensional poverty measurement: A statistical approach with applications</title>
  <meta name="description" content="Chapter 6 Scale equating and linking | Multidimensional poverty measurement: A statistical approach with applications" />
  <meta name="generator" content="bookdown 0.10 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Scale equating and linking | Multidimensional poverty measurement: A statistical approach with applications" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Scale equating and linking | Multidimensional poverty measurement: A statistical approach with applications" />
  
  
  

<meta name="author" content="Héctor Nájera with help from other academics collaborating in this project (please cite this draft)" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="Chapter-5.html">
<link rel="next" href="identifying-the-poor-group.html">
<script src="assets/jquery-2.2.3/jquery.min.js"></script>
<link href="assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="Chapter-1.html"><a href="Chapter-1.html"><i class="fa fa-check"></i><b>1</b> Poverty and measurement theory principles</a><ul>
<li class="chapter" data-level="1.1" data-path="Chapter-1.html"><a href="Chapter-1.html#the-concept-of-poverty"><i class="fa fa-check"></i><b>1.1</b> The Concept of Poverty</a></li>
<li class="chapter" data-level="1.2" data-path="Chapter-1.html"><a href="Chapter-1.html#Chapter-1-dimensions"><i class="fa fa-check"></i><b>1.2</b> Theoretical dimensions of poverty</a></li>
<li class="chapter" data-level="1.3" data-path="Chapter-1.html"><a href="Chapter-1.html#the-measurement-of-poverty-and-its-challenges"><i class="fa fa-check"></i><b>1.3</b> The measurement of poverty and its challenges</a><ul>
<li class="chapter" data-level="1.3.1" data-path="Chapter-1.html"><a href="Chapter-1.html#challenges-in-selection-of-dimensions-contents-cut-offs-and-weights"><i class="fa fa-check"></i><b>1.3.1</b> Challenges in selection of dimensions, contents, cut offs and weights</a></li>
<li class="chapter" data-level="1.3.2" data-path="Chapter-1.html"><a href="Chapter-1.html#challenges-in-aggregation-and-identification-of-the-poor"><i class="fa fa-check"></i><b>1.3.2</b> Challenges in aggregation and identification of the poor</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="Chapter-1.html"><a href="Chapter-1.html#the-poor-and-the-not-poor-the-poverty-line"><i class="fa fa-check"></i><b>1.4</b> The poor and the not poor: The poverty line</a></li>
<li class="chapter" data-level="1.5" data-path="Chapter-1.html"><a href="Chapter-1.html#a-brief-on-multidimensional-poverty-measurement"><i class="fa fa-check"></i><b>1.5</b> A brief on multidimensional poverty measurement</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chapter-2.html"><a href="Chapter-2.html"><i class="fa fa-check"></i><b>2</b> Poverty and measurement theory: A statistical framework</a><ul>
<li class="chapter" data-level="2.1" data-path="Chapter-2.html"><a href="Chapter-2.html#workflow-in-poverty-measurement-a-falsifiable-framework"><i class="fa fa-check"></i><b>2.1</b> Workflow in poverty measurement: A falsifiable framework</a></li>
<li class="chapter" data-level="2.2" data-path="Chapter-2.html"><a href="Chapter-2.html#samplingspace"><i class="fa fa-check"></i><b>2.2</b> Identification of the sampling space</a></li>
<li class="chapter" data-level="2.3" data-path="Chapter-2.html"><a href="Chapter-2.html#selection-of-dimensions-and-indicators"><i class="fa fa-check"></i><b>2.3</b> Selection of dimensions and indicators</a></li>
<li class="chapter" data-level="2.4" data-path="Chapter-2.html"><a href="Chapter-2.html#aggregation-and-weighting"><i class="fa fa-check"></i><b>2.4</b> Aggregation and weighting</a><ul>
<li class="chapter" data-level="2.4.1" data-path="Chapter-2.html"><a href="Chapter-2.html#splitting-the-population-into-meaningful-groups"><i class="fa fa-check"></i><b>2.4.1</b> Splitting the population into meaningful groups</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="Chapter-2.html"><a href="Chapter-2.html#measurement-theory-as-an-statistical-framework"><i class="fa fa-check"></i><b>2.5</b> Measurement theory as an statistical framework</a></li>
<li class="chapter" data-level="2.6" data-path="Chapter-2.html"><a href="Chapter-2.html#poverty-and-error-in-measurement"><i class="fa fa-check"></i><b>2.6</b> Poverty and error in measurement</a></li>
<li class="chapter" data-level="2.7" data-path="Chapter-2.html"><a href="Chapter-2.html#measurement-model-for-poverty"><i class="fa fa-check"></i><b>2.7</b> Measurement model for poverty</a></li>
<li class="chapter" data-level="2.8" data-path="Chapter-2.html"><a href="Chapter-2.html#Chapter-2-blueprint"><i class="fa fa-check"></i><b>2.8</b> Blueprints and poverty measurement models</a></li>
<li class="chapter" data-level="2.9" data-path="Chapter-2.html"><a href="Chapter-2.html#measurement-theory-and-principles"><i class="fa fa-check"></i><b>2.9</b> Measurement theory and principles</a><ul>
<li class="chapter" data-level="2.9.1" data-path="Chapter-2.html"><a href="Chapter-2.html#origins-of-measurement-theory"><i class="fa fa-check"></i><b>2.9.1</b> Origins of measurement theory</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Chapter-3.html"><a href="Chapter-3.html"><i class="fa fa-check"></i><b>3</b> Reliability in poverty measurement</a><ul>
<li class="chapter" data-level="3.1" data-path="Chapter-3.html"><a href="Chapter-3.html#intuition-to-the-concept-of-reliability"><i class="fa fa-check"></i><b>3.1</b> Intuition to the concept of reliability</a></li>
<li class="chapter" data-level="3.2" data-path="Chapter-3.html"><a href="Chapter-3.html#reliability-theory"><i class="fa fa-check"></i><b>3.2</b> Reliability theory</a></li>
<li class="chapter" data-level="3.3" data-path="Chapter-3.html"><a href="Chapter-3.html#Chapter-3-measuresrel"><i class="fa fa-check"></i><b>3.3</b> Statistical measures of reliability</a></li>
<li class="chapter" data-level="3.4" data-path="Chapter-3.html"><a href="Chapter-3.html#itemlevelrel"><i class="fa fa-check"></i><b>3.4</b> Item-level reliability and weighting</a></li>
<li class="chapter" data-level="3.5" data-path="Chapter-3.html"><a href="Chapter-3.html#relestimation"><i class="fa fa-check"></i><b>3.5</b> Estimation of Reliability</a><ul>
<li class="chapter" data-level="3.5.1" data-path="Chapter-3.html"><a href="Chapter-3.html#overall-reliability"><i class="fa fa-check"></i><b>3.5.1</b> Overall reliability</a></li>
<li class="chapter" data-level="3.5.2" data-path="Chapter-3.html"><a href="Chapter-3.html#Chapter-3-expoverel"><i class="fa fa-check"></i><b>3.5.2</b> Exploratory (non-model based) estimation of overall reliability</a></li>
<li class="chapter" data-level="3.5.3" data-path="Chapter-3.html"><a href="Chapter-3.html#model-based-estimation-of-overall-reliability"><i class="fa fa-check"></i><b>3.5.3</b> Model-based estimation of overall reliability</a></li>
<li class="chapter" data-level="3.5.4" data-path="Chapter-3.html"><a href="Chapter-3.html#overall-reliability-and-population-orderings"><i class="fa fa-check"></i><b>3.5.4</b> Overall reliability and population orderings</a></li>
<li class="chapter" data-level="3.5.5" data-path="Chapter-3.html"><a href="Chapter-3.html#item-level-reliability"><i class="fa fa-check"></i><b>3.5.5</b> Item-level reliability</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="Chapter-3.html"><a href="Chapter-3.html#multidimensional-item-reliability-evaluation"><i class="fa fa-check"></i><b>3.6</b> Multidimensional item-reliability evaluation</a><ul>
<li class="chapter" data-level="3.6.1" data-path="Chapter-3.html"><a href="Chapter-3.html#item-reliability-and-monotonicity"><i class="fa fa-check"></i><b>3.6.1</b> Item-reliability and monotonicity</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="Chapter-3.html"><a href="Chapter-3.html#real-data-example"><i class="fa fa-check"></i><b>3.7</b> Real data example</a><ul>
<li class="chapter" data-level="3.7.1" data-path="Chapter-3.html"><a href="Chapter-3.html#overall-reliability-1"><i class="fa fa-check"></i><b>3.7.1</b> Overall reliability</a></li>
<li class="chapter" data-level="3.7.2" data-path="Chapter-3.html"><a href="Chapter-3.html#item-level-reliability-1"><i class="fa fa-check"></i><b>3.7.2</b> Item-level reliability</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Chapter-4.html"><a href="Chapter-4.html"><i class="fa fa-check"></i><b>4</b> Validity in poverty measurement</a><ul>
<li class="chapter" data-level="4.1" data-path="Chapter-4.html"><a href="Chapter-4.html#intuition-to-the-concept-of-validity"><i class="fa fa-check"></i><b>4.1</b> Intuition to the concept of validity</a></li>
<li class="chapter" data-level="4.2" data-path="Chapter-4.html"><a href="Chapter-4.html#theory-of-validity"><i class="fa fa-check"></i><b>4.2</b> Theory of validity</a></li>
<li class="chapter" data-level="4.3" data-path="Chapter-4.html"><a href="Chapter-4.html#methods-for-the-analysis-validity"><i class="fa fa-check"></i><b>4.3</b> Methods for the analysis validity</a><ul>
<li class="chapter" data-level="4.3.1" data-path="Chapter-4.html"><a href="Chapter-4.html#criterion-validity"><i class="fa fa-check"></i><b>4.3.1</b> Criterion validity</a></li>
<li class="chapter" data-level="4.3.2" data-path="Chapter-4.html"><a href="Chapter-4.html#construct-validity"><i class="fa fa-check"></i><b>4.3.2</b> Construct validity</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="Chapter-4.html"><a href="Chapter-4.html#validity-assessment"><i class="fa fa-check"></i><b>4.4</b> Validity assessment</a><ul>
<li class="chapter" data-level="4.4.1" data-path="Chapter-4.html"><a href="Chapter-4.html#criterion-validity-1"><i class="fa fa-check"></i><b>4.4.1</b> Criterion Validity</a></li>
<li class="chapter" data-level="4.4.2" data-path="Chapter-4.html"><a href="Chapter-4.html#construct-validity-1"><i class="fa fa-check"></i><b>4.4.2</b> Construct Validity</a></li>
<li class="chapter" data-level="4.4.3" data-path="Chapter-4.html"><a href="Chapter-4.html#a-joint-assessment-criterion-and-construct-validity"><i class="fa fa-check"></i><b>4.4.3</b> A joint assessment: Criterion and construct validity</a></li>
<li class="chapter" data-level="4.4.4" data-path="Chapter-4.html"><a href="Chapter-4.html#real-data-example-1"><i class="fa fa-check"></i><b>4.4.4</b> Real-data example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Chapter-5.html"><a href="Chapter-5.html"><i class="fa fa-check"></i><b>5</b> Comparability in poverty measurement</a><ul>
<li class="chapter" data-level="5.1" data-path="Chapter-5.html"><a href="Chapter-5.html#measurement-invariance"><i class="fa fa-check"></i><b>5.1</b> Measurement invariance</a></li>
<li class="chapter" data-level="5.2" data-path="Chapter-5.html"><a href="Chapter-5.html#introduction-to-key-aspects-of-measurement-invariance"><i class="fa fa-check"></i><b>5.2</b> Introduction to key aspects of measurement invariance</a></li>
<li class="chapter" data-level="5.3" data-path="Chapter-5.html"><a href="Chapter-5.html#methods-for-the-assessment-of-measurement-invariance"><i class="fa fa-check"></i><b>5.3</b> Methods for the assessment of Measurement Invariance</a><ul>
<li class="chapter" data-level="5.3.1" data-path="Chapter-5.html"><a href="Chapter-5.html#multiple-group-factor-analysis"><i class="fa fa-check"></i><b>5.3.1</b> Multiple Group Factor Analysis</a></li>
<li class="chapter" data-level="5.3.2" data-path="Chapter-5.html"><a href="Chapter-5.html#the-alignment-method"><i class="fa fa-check"></i><b>5.3.2</b> The alignment method</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="Chapter-5.html"><a href="Chapter-5.html#real-data-analysis-of-measurement-invariance"><i class="fa fa-check"></i><b>5.4</b> Real-data analysis of Measurement Invariance</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="scale-equating-and-linking.html"><a href="scale-equating-and-linking.html"><i class="fa fa-check"></i><b>6</b> Scale equating and linking</a><ul>
<li class="chapter" data-level="6.1" data-path="scale-equating-and-linking.html"><a href="scale-equating-and-linking.html#intuition-to-scale-equating"><i class="fa fa-check"></i><b>6.1</b> Intuition to scale equating</a></li>
<li class="chapter" data-level="6.2" data-path="scale-equating-and-linking.html"><a href="scale-equating-and-linking.html#theory-of-scale-equating"><i class="fa fa-check"></i><b>6.2</b> Theory of scale equating</a><ul>
<li class="chapter" data-level="6.2.1" data-path="scale-equating-and-linking.html"><a href="scale-equating-and-linking.html#workflow-in-scale-equating"><i class="fa fa-check"></i><b>6.2.1</b> Workflow in scale equating</a></li>
<li class="chapter" data-level="6.2.2" data-path="scale-equating-and-linking.html"><a href="scale-equating-and-linking.html#theory-of-irt-scale-equating"><i class="fa fa-check"></i><b>6.2.2</b> Theory of IRT scale equating</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="scale-equating-and-linking.html"><a href="scale-equating-and-linking.html#example-of-irt-equating-with-simulated-data-in-r"><i class="fa fa-check"></i><b>6.3</b> Example of IRT equating with simulated data in R</a></li>
<li class="chapter" data-level="6.4" data-path="scale-equating-and-linking.html"><a href="scale-equating-and-linking.html#real-data-example-2"><i class="fa fa-check"></i><b>6.4</b> Real-data example</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="identifying-the-poor-group.html"><a href="identifying-the-poor-group.html"><i class="fa fa-check"></i><b>7</b> Identifying the poor group</a><ul>
<li class="chapter" data-level="7.1" data-path="identifying-the-poor-group.html"><a href="identifying-the-poor-group.html#the-poverty-line"><i class="fa fa-check"></i><b>7.1</b> The poverty line</a></li>
<li class="chapter" data-level="7.2" data-path="identifying-the-poor-group.html"><a href="identifying-the-poor-group.html#perspectives-on-the-poverty-line-union-and-intersection-approaches"><i class="fa fa-check"></i><b>7.2</b> Perspectives on the poverty line: Union and intersection approaches</a></li>
<li class="chapter" data-level="7.3" data-path="identifying-the-poor-group.html"><a href="identifying-the-poor-group.html#the-human-rights-based-approach"><i class="fa fa-check"></i><b>7.3</b> The human rights-based approach</a></li>
<li class="chapter" data-level="7.4" data-path="identifying-the-poor-group.html"><a href="identifying-the-poor-group.html#the-ubn-weighted-approach"><i class="fa fa-check"></i><b>7.4</b> The UBN weighted approach</a></li>
<li class="chapter" data-level="7.5" data-path="identifying-the-poor-group.html"><a href="identifying-the-poor-group.html#the-partially-weighted-approach"><i class="fa fa-check"></i><b>7.5</b> The partially-weighted approach</a></li>
<li class="chapter" data-level="7.6" data-path="identifying-the-poor-group.html"><a href="identifying-the-poor-group.html#the-bristol-optimal-approach"><i class="fa fa-check"></i><b>7.6</b> The Bristol Optimal approach</a></li>
<li class="chapter" data-level="7.7" data-path="identifying-the-poor-group.html"><a href="identifying-the-poor-group.html#example-with-simulated-data"><i class="fa fa-check"></i><b>7.7</b> Example with simulated data</a></li>
<li class="chapter" data-level="7.8" data-path="identifying-the-poor-group.html"><a href="identifying-the-poor-group.html#real-data-analysis"><i class="fa fa-check"></i><b>7.8</b> Real-data analysis</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="final-thoughts.html"><a href="final-thoughts.html"><i class="fa fa-check"></i><b>8</b> Final thoughts</a><ul>
<li class="chapter" data-level="8.1" data-path="final-thoughts.html"><a href="final-thoughts.html#the-future-of-data-production-in-multidimensional-poverty-measurement"><i class="fa fa-check"></i><b>8.1</b> The future of data production in multidimensional poverty measurement</a></li>
<li class="chapter" data-level="8.2" data-path="final-thoughts.html"><a href="final-thoughts.html#advanced-topics-in-multidimensional-poverty-measurement"><i class="fa fa-check"></i><b>8.2</b> Advanced topics in multidimensional poverty measurement</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>9</b> References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Multidimensional poverty measurement: A statistical approach with applications</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="scale-equating-and-linking" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Scale equating and linking</h1>
<p><strong>Abstract</strong></p>
<p>This chapter focuses on a framework to make scales comparable across groups, countries and time points. It describes the theory of scale equating which proposes that two or more indices, with some indicators in common but not necessarily the same, can be made comparable via modelling. The chapter focuses in one form of equating: Item Response Theory equating because it is widely used, and it fits more naturally with the whole rationale of the book. Several examples are used to illustrate the main concepts and its implementation in <strong>R</strong>.</p>
<div id="intuition-to-scale-equating" class="section level2">
<h2><span class="header-section-number">6.1</span> Intuition to scale equating</h2>
<p>Previous chapter introduces the sources affecting the comparability of different poverty indices and presents the concept and empirical implementation of measurement invariance. In poverty research, households are ranked according to some indicators of (low) material and social deprivation using survey or census data. The indicators in question have a structure (unidimensional or multidimensional, See chapter <a href="Chapter-1.html#Chapter-1">1</a>) for the general population. One problem is that such a measurement model might not be adequate for a different population (such as countries) or for a different year. We saw in previous chapter that in statistical terms this means that the measurement model is not equivalent across groups. We now know that, once a MI assessment has been conducted, poverty can be compared on the factor using the alignment method. This, however, might not be fully satisfactory for policy makers as the values of a standardized latent variable make little practical sense. Furthermore, it is unclear how to use these values to set a poverty line.</p>
<p>Another critical problem is that MI is adequate when scales have the same items and it does not solve the problem of working with scales that have different items or that have been upgraded in accordance with the living standards. Ideally, once measurement invariance is assessed researches would like to put everything into a meaningful metric and being able to compare measures that might have suffered from changes in its contents. Moreover, one question in poverty research is about how the severity of poverty is affected by changes in living standards and how this can be tractable using the available data. Thus, poverty measures need to be equated or equivalised in some way so that we can make meaningful comparisons across groups or time.</p>
<p>Scale or test equating is the answer from measurement theory to the problem of working with scales that are not necessarily equivalent across countries, time points, etc. The academic concern with making scores comparable has a history of more than 90 years <span class="citation">(Holland, <a href="references.html#ref-Holland2007" role="doc-biblioref">2007</a>)</span>. The modern development of the theory of scale equating can be traced back to the 1980s <span class="citation">(Haebara, <a href="references.html#ref-Haebara1980" role="doc-biblioref">1980</a>; Kolen, <a href="references.html#ref-Kolen1988" role="doc-biblioref">1988</a>; Petersen, Cook, &amp; Stocking, <a href="references.html#ref-Petersen1983" role="doc-biblioref">1983</a>)</span>. However, after the publication of <span class="citation">Kolen &amp; Brennan (<a href="references.html#ref-Kolen2004" role="doc-biblioref">2004</a>)</span>’s seminal book, this framework has become more accessible through software development and implemented in several fields and has been under constant development <span class="citation">(Davier, <a href="references.html#ref-Davier2010" role="doc-biblioref">2010</a>; González &amp; Wiberg, <a href="references.html#ref-Gonzalez2017" role="doc-biblioref">2017</a>)</span>.</p>
<p>Educational testing has been the field at the forefront of scale equating. Admissions to universities often depend on the score of a test. But what if this test favours some students? and What if different versions of the tests are implemented? This poses a challenge for the admissions’ office for two students might have different scores but just because the tests had different difficulties, i.e. one was easier than other.</p>
<p>How does this problem translate to poverty measurement? There are two good examples to see this happening to our scales. According to <span class="citation">Townsend (<a href="references.html#ref-Townsend1979" role="doc-biblioref">1979</a>)</span> poverty is relative across time and space. The <em>space</em> to identify the dimensions and indicators of poverty in the early 20th Century would look very different from the <em>space</em> of things and activities necessary to live with dignity in the 21st Century. For example, overcrowding and access to electricity were very good indicators of poverty in London but these days is no longer the case. That means that the two measure will have different deprivation indicators. So, what does it mean that someone in the early 20th century had a deprivation score equal to 6 relative to someone that has a score equal to 3 today? Is it possible to compare how severely deprived they are? And how this might or might not impact the prevalence rate?</p>
<p>This is a very crude example, but it helps to illustrate some of the challenges when comparing poverty overtime. However, in poverty research one common belief is that using the same indicators is sufficient to make valid comparisons across groups. Leaving aside the data collection and sampling issues associated with MI, we could think carefully about this assumption. Imagine that we use indicators of the early 20th to measure poverty today. Then we have two people with the same deprivation pattern- they lack electricity, cook with charcoal, and live in an overcrowded house. Hence, they have the same deprivation scores. In the early 20th century it would not be very difficult to find such conditions in a small random sample. However, these days this situation would denote acute material deprivation. But these two people will have the same deprivation score, so without equating they would be equally deprived. How sensible is this conclusion? Well, not very.</p>
<p>Scale equating aims at adjusting the differences in severity between tests and groups. The process of equating, given the response patterns, will notice that it is <em>more difficult</em> (as in Item Response Theory modelling) today being deprived of the items in question than 100 years ago. So, based on difficulty, the contemporary scale will be adjusted in terms of the early 20th Century’s scale. If the equating process is successful, it should make sense and a score equal 3 today would mean something more severe in terms of a score equal 3 100 years ago, i.e. it will be higher. The inflation of today’s score will be the result of equating and it will tell us a lot of useful information to adjust our conclusions about poverty and severity of deprivation.</p>
<p>The second example focuses on the practical use of equating. Statistical offices tend to update their indices overtime, or we tend to have countries with two different measures but with some common indicators. So, they drop so indicators and include some new indicators. This just adds to the frustration of policymakers and academics because comparability is lost. One way to tackle this problem is scale equating. Figure @(fig:changeEQ) displays a common situation in which the indicators have changed from measure A (Poverty) to measure B (Poverty B). There are seven items that appear in both measures and two items that were dropped and other two that were included.</p>
<div class="figure" style="text-align: center"><span id="fig:changeEQ"></span>
<img src="Diagram_EQ_1.png" alt="This figure shows the case in which there is a modification in the contents of a measure. In red there are the common items between the two measures" width="2396" />
<p class="caption">
Figure 6.1: This figure shows the case in which there is a modification in the contents of a measure. In red there are the common items between the two measures
</p>
</div>
<p>One crucial aspect of the example above is that if we have to tests with a common subset of items, then we can assess not only the effect of the updating of the scale but also, we could link both measures and make them comparable across time points. We will see that for scale equating to work we need to identify as many <strong>anchors</strong> as we can, i.e. items that respect measurement invariance across tests. In this case we have seven potential candidates. In the following we introduce formally the concepts and methods to conduct scale equating. We will, of course, discuss some limitations of this approach as it might be sensible in all situations or desirable.</p>
</div>
<div id="theory-of-scale-equating" class="section level2">
<h2><span class="header-section-number">6.2</span> Theory of scale equating</h2>
<div id="workflow-in-scale-equating" class="section level3">
<h3><span class="header-section-number">6.2.1</span> Workflow in scale equating</h3>
<p>Drawing upon <span class="citation">Davier (<a href="references.html#ref-Davier2010" role="doc-biblioref">2010</a>)</span>, before formally introducing scale equating, we will present some of the stages involved in this process.</p>
<ol style="list-style-type: decimal">
<li><p>Two or more poverty indices (test forms using the vocabulary in scale equating): We will have two indices and one research question: How to measure and compare the latent poverty levels of the population regardless of which index we use.</p></li>
<li><p>Detecting confounding differences: The task is to measure the latent poverty levels by avoiding the confounding effect of using indices that look at more or less acute deprivation indicators with the effect of latent poverty. This implies figuring out the differences between the estimated severities/difficulties of the indicators and the underlying latent level of poverty.</p></li>
<li><p>Modelling the data generating process: Looking at different modelling alternatives, check their assumptions and assess how sensible using a given model is. There are several methods, observed score equating, IRT equating, kernel equating, etc.</p></li>
<li><p>Error in equating: All models are wrong and thus it is vital to assess the extent to which the results of our model are useless or reasonable given the errors of the parameters that are being estimated.</p></li>
</ol>
</div>
<div id="theory-of-irt-scale-equating" class="section level3">
<h3><span class="header-section-number">6.2.2</span> Theory of IRT scale equating</h3>
<p>In this edition of this book, we will focus on one of the most widely used form of equating: Item Response Theory (IRT) equating because it is a framework that has been used for reliability analysis and fits more naturally with the kind of thinking behind this book: Poverty is a concept and its measurement is based on reflective models where deprivation is a cause of poverty. Thus, people have a latent level of poverty that produces observed deprivation scores.</p>
<p>Chapter <a href="Chapter-2.html#Chapter-2">2</a> underline the importance of explicitly working with models and blueprints in multidimensional poverty measurement. We proposed in equation <a href="Chapter-2.html#eq:mainmodel">(2.1)</a> a very simple model that looks as follows:</p>
<p><span class="math display" id="eq:mainmodel">\[\begin{equation}
\tag{2.1}
\mathscr F = \{\mathscr X, F_{\theta} : \theta \in \Theta\}
\end{equation}\]</span></p>
<p>where the variables <span class="math inline">\(x_1,...,x_n\)</span> follow a certain distribution <span class="math inline">\(F_{\theta}\)</span>, which is indexed by a parameter <span class="math inline">\(\theta\)</span> defined in the parameter space <span class="math inline">\(\Theta\)</span>. <span class="math inline">\(\mathscr F\)</span> is a family of all probability distributions on <span class="math inline">\(\mathscr X\)</span>, which is just the set of all possible observed data.</p>
<p>We will borrow the formulation of <span class="citation">González &amp; Wiberg (<a href="references.html#ref-Gonzalez2017" role="doc-biblioref">2017</a>)</span> notation to formulate the equating model based on Item Response Theory, as this will be the method that we will use in the book, as it is consistent with the methods and rationale that we have used so far in the book.</p>
<p>For example, Item Response Theory (IRT) models, which are widely used in test equating, take the following general form:</p>
<p><span class="math display" id="eq:irtmodel">\[\begin{equation}
\tag{6.1}
\mathscr F = {{0,1}, Bernoulli[\pi(\alpha_i, \omega_j)]:(\alpha_i, \omega_j) \in \mathbb{R} x \mathbb{R}}
\end{equation}\]</span></p>
<p>For a two-parameter IRT model we would have <span class="math inline">\(x_{ij}\)</span> denoting a binary deprivation indicator of an individual <span class="math inline">\(i\)</span> who poverty is measured based on the index <span class="math inline">\(j\)</span>. That means that the probability of being deprived is given by: <span class="math inline">\((x_{ij} | \theta_i, a_j, b_j) \sim Bernoulli\)</span>, where <span class="math inline">\(\theta_i\)</span> is person’s latent poverty, <span class="math inline">\(a_j\)</span> is the discrimination of the item, <span class="math inline">\(b_j\)</span> is the severity of the item. () is the item characteristic curve (ICC).</p>
<p>The key parameters in this example are thus <span class="math inline">\(\theta_i, a_j, b_j\)</span>. In the case that we have two indices <span class="math inline">\((j=2)\)</span> we would like to link in some way the parameters of the first index (<span class="math inline">\(X\)</span>) with the second index (<span class="math inline">\(Y\)</span>). This could be achieved by estimating an IRT model for each index, extracting the parameters in question and then apply a linear equation to convert the IRT scores as:</p>
<p><span class="math display" id="eq:irtequating1">\[\begin{equation}
\tag{6.2}
\theta_{yi} =  A\theta_{xi} + B
\end{equation}\]</span></p>
<p>To relate the parameters between the two tests we use the following:</p>
<p><span class="math display" id="eq:irtequating2">\[\begin{equation}
\tag{6.3}
a_{yj} =  a_{xj} / A
\end{equation}\]</span></p>
<p><span class="math display" id="eq:irtequating2">\[\begin{equation}
\tag{6.3}
b_{yj} =  Ab_{xj} + B
\end{equation}\]</span></p>
<p>where A and B are the equating coefficients and these need to be estimated using different methods such as mean-sigma, mean-geometric, Haebara, Stocking-Lord [<span class="citation">González &amp; Wiberg (<a href="references.html#ref-Gonzalez2017" role="doc-biblioref">2017</a>)</span>; Davier2010]. Once these parameters have been estimated, the next step consists in putting the index <span class="math inline">\(X\)</span> in terms of the index <span class="math inline">\(Y\)</span>. This process assumes that scores are equated considering the latent level of poverty which relates to observed score. There are two perspectives to do so: Observed-score equating and True-score equating <span class="citation">(Kolen &amp; Brennan, <a href="references.html#ref-Kolen2004" role="doc-biblioref">2004</a>)</span>. We explain these two very briefly:</p>
<p>Observed-score equating is based on the actual marginal score distributions (i.e. imagine a histogram of a deprivation score. This kind of equating uses the IRT model to adjust the score distributions across parallel forms, i.e. indices. To do so an observed score is calculated at each specified value of latent poverty level (remember that the metric of this variable is <span class="math inline">\(\theta \sim (0,\sigma^2)\)</span>). This is summed/integrated across all levels of latent poverty to produce a marginal score distribution. The equipercentile is applied to establish the relationship between the two observed scores.</p>
<p>True-score equating draws on the idea of a true score from Classical Test Theory (CTT). The whole idea is that people with the same level of latent poverty <span class="math inline">\(\theta_j\)</span> should have an equivalent true score, regardless the differences between tests. First, a latent poverty level (<span class="math inline">\(\theta_j\)</span>, where <span class="math inline">\(j=1\)</span>) is associated with a true score via the Newton-Rapson method. Then the true score of the A index is mapped into the index B using the same latent poverty level (<span class="math inline">\(\theta_j\)</span>, where <span class="math inline">\(j=2\)</span>). This procedure is often applied for each integer of the deprivation score.</p>
</div>
</div>
<div id="example-of-irt-equating-with-simulated-data-in-r" class="section level2">
<h2><span class="header-section-number">6.3</span> Example of IRT equating with simulated data in R</h2>
<p>To introduce IRT equating we will use two simulated indices (<strong>A</strong> and <strong>B</strong>) that capture a the simplest situation in equating and in poverty measurement. Both indices are comprised of 15 binary indicators (<span class="math inline">\(n=5000\)</span>). The first 11 indicators are the same in that they are measurement invariance and have the same severities and discrimination values. The remaining four indicators have different severities. The indicators of index A are more severe than the indicators of index B. This is a situation in which two very similar indices are applied to the same population -with no changes in the underlying level of poverty- but one is more severe than another. So, it is not possible to compare the observed deprivation scores directly. This could be also depicting a situation where two similar countries with similar living standards are compared using similar indices.</p>
<p>The data corresponding to index A is stored on the <code>EQ_IRT_1_1.dat</code> file and the data corresponding to index B is on the file <code>EQ_IRT_2_1.dat</code>. To familiarise ourselves with the data we will have a look at the files:</p>
<pre class="sourceCode r"><code class="sourceCode r">A&lt;-<span class="kw">read.table</span>(<span class="st">&quot;EQ_IRT_1_1.dat&quot;</span>)
B&lt;-<span class="kw">read.table</span>(<span class="st">&quot;EQ_IRT_2_1.dat&quot;</span>)</code></pre>
<p>We now tabulate the deprivation rates for each one of the 15 indicators so that we can appreciate the similarities and differences between the two samples. We see that there are just small variations in the first 11 items and larger variations for the remaining four. This is the expected behaviour given that we said that the latent levels of poverty are the same between samples A and B.</p>
<pre class="sourceCode r"><code class="sourceCode r">dep_propA&lt;-<span class="kw">unlist</span>(<span class="kw">lapply</span>(A, <span class="cf">function</span>(x) <span class="kw">mean</span>(x)))
dep_propA&lt;-<span class="kw">round</span>(dep_propA[<span class="dv">1</span><span class="op">:</span><span class="dv">15</span>]<span class="op">*</span><span class="dv">100</span>,<span class="dv">0</span>)
dep_propA</code></pre>
<pre><code>##  V1  V2  V3  V4  V5  V6  V7  V8  V9 V10 V11 V12 V13 V14 V15 
##  12  28  17  17  25  31  37  15  17  10  22  20  16  13  10</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">dep_propB&lt;-<span class="kw">unlist</span>(<span class="kw">lapply</span>(B, <span class="cf">function</span>(x) <span class="kw">mean</span>(x)))
dep_propB&lt;-<span class="kw">round</span>(dep_propB[<span class="dv">1</span><span class="op">:</span><span class="dv">15</span>]<span class="op">*</span><span class="dv">100</span>,<span class="dv">0</span>)
dep_propB</code></pre>
<pre><code>##  V1  V2  V3  V4  V5  V6  V7  V8  V9 V10 V11 V12 V13 V14 V15 
##  12  29  17  17  28  32  37  17  17  11  21  28  24  20  19</code></pre>
<p>The first step in IRT-test equating consist in fitting and IRT model for each one of the two indices. If we think this carefully, this just a more formal way to compare the measurement properties of index A and B. That is, whether the indicators discriminate well between the poor and the not poor and what latent level of severity of poverty each indicator is capturing.</p>
<p>The models will be fitted on <strong>Mplus</strong> via <strong>R</strong> using the <code>mplusAutomation()</code> function <span class="citation">(Hallquist &amp; Wiley, <a href="references.html#ref-Hallquist2018" role="doc-biblioref">2018</a>)</span>. We will write a more complex function because we will like to offer readers to run simulations to check the properties of equating, this is why we left and <code>i</code> in the commands.</p>
<p>Here we fit the IRT model for both indices. We will create one script for each index (<code>EQ_IRT_1_1.inp</code> for index A for example):</p>
<pre class="sourceCode r"><code class="sourceCode r">test&lt;-<span class="kw">mplusObject</span>(<span class="dt">VARIABLE =</span> <span class="st">&quot;NAMES=V1-V15; </span>
<span class="st">                  USEVARIABLES=V1-V15; </span>
<span class="st">                  CATEGORICAL = V1-V15;&quot;</span>, 
                  <span class="dt">MODEL=</span> <span class="st">&quot;f by V1-V15*;</span>
<span class="st">                                  f@1;&quot;</span>)

<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>){
  <span class="kw">mplusModeler</span>(test, <span class="dt">modelout=</span><span class="kw">paste</span>(<span class="st">&quot;EQ_IRT_&quot;</span>,i,<span class="st">&quot;_1&quot;</span>,<span class="st">&quot;.inp&quot;</span>,<span class="dt">sep=</span><span class="st">&quot;&quot;</span>),  <span class="dt">writeData =</span> <span class="st">&quot;never&quot;</span>,
               <span class="dt">hashfilename =</span> <span class="ot">FALSE</span>)
}</code></pre>
<p>Now we request <code>mplusAutomation()</code> to run both models on <strong>Mplus</strong> for us as follows:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>){
<span class="kw">runModels</span>(<span class="kw">paste</span>(<span class="st">&quot;EQ_IRT_&quot;</span>,i,<span class="st">&quot;_1&quot;</span>,<span class="st">&quot;.inp&quot;</span>,<span class="dt">sep=</span><span class="st">&quot;&quot;</span>))
}</code></pre>
<p>Finally we read the models using the <code>readModels()</code> function. We will store the files in the objects <code>irt_1</code> and <code>irt_2</code> and then we will put them in a list so that we can put them in the correct format for the equating (i.e. the irt parameters <em>a, b and c</em> of each item need to be in columns). So, using <code>lapply()</code> we can put them in the correct format and store them on the <code>irtS</code> list.</p>
<pre class="sourceCode r"><code class="sourceCode r">irt_<span class="dv">1</span>&lt;-<span class="kw">readModels</span>(<span class="dt">filefilter =</span><span class="st">&quot;EQ_IRT_1&quot;</span>)</code></pre>
<pre><code>## Reading model:  C:/Proyectos Investigacion/PM Book/eq_irt_1_1.out</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">irt_<span class="dv">2</span>&lt;-<span class="kw">readModels</span>(<span class="dt">filefilter =</span><span class="st">&quot;EQ_IRT_2&quot;</span>)</code></pre>
<pre><code>## Reading model:  C:/Proyectos Investigacion/PM Book/eq_irt_2_1.out</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">irtS&lt;-<span class="kw">list</span>(irt_<span class="dv">1</span>,irt_<span class="dv">2</span>)


irtS&lt;-<span class="kw">lapply</span>(irtS, <span class="cf">function</span>(x) {
  x&lt;-x<span class="op">$</span>parameters<span class="op">$</span>irt.parameterization
  x&lt;-x[<span class="dv">1</span><span class="op">:</span><span class="dv">30</span>,]
  x&lt;-<span class="kw">data.frame</span>(<span class="dt">a=</span>x<span class="op">$</span>est[<span class="dv">1</span><span class="op">:</span><span class="dv">15</span>],<span class="dt">b=</span>x<span class="op">$</span>est[<span class="dv">16</span><span class="op">:</span><span class="dv">30</span>],<span class="dt">c=</span><span class="dv">0</span>)
  x
}
)</code></pre>
<p>The <code>irtS</code> list contains the parameters of indices A and B. We will rename them to facilitate the specification using the excellent <code>SNSequate</code> package <span class="citation">(González &amp; others, <a href="references.html#ref-Gonzalez2014" role="doc-biblioref">2014</a>)</span>. We need to tell <code>SNSequate</code> the dataframes containing the IRT-parameters of each test and which items are the <em>anchors</em> -common items-.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(SNSequate)
parm.a&lt;-irtS[[<span class="dv">1</span>]]
parm.b&lt;-irtS[[<span class="dv">2</span>]]
comitems&lt;-(<span class="dv">1</span><span class="op">:</span><span class="dv">11</span>)
parm &lt;-<span class="st"> </span><span class="kw">cbind</span>(parm.a, parm.b)</code></pre>
<p>The key function to conduct IRT-equating is <code>irt.link()</code>, this function uses the parameters, takes into account the common items and considers which kind of IRT we want to use, in this case a two-parameter model. In this case we will use 1.7 for the constant D, as it is common practice.</p>
<pre class="sourceCode r"><code class="sourceCode r">eqconst&lt;-<span class="kw">irt.link</span>(parm, comitems, <span class="dt">model =</span> <span class="st">&quot;2PL&quot;</span>, <span class="dt">icc =</span> <span class="st">&quot;logistic&quot;</span>, <span class="dt">D =</span> <span class="fl">1.7</span>)</code></pre>
<p>The object <code>eqconst</code> contains the estimated constants for equating: a and b. It will estimate these constants using different methods (mean-mean, StockLord, Haebara). For this example, we will use the constants from the StockLord method. We simply extract the constants as follows:</p>
<pre class="sourceCode r"><code class="sourceCode r">Sl_a&lt;-eqconst<span class="op">$</span>StockLord[<span class="dv">1</span>]  
Sl_b&lt;-eqconst<span class="op">$</span>StockLord[<span class="dv">2</span>] </code></pre>
<p>The next step is to apply the contents to the IRT coefficients. What we need to do is to rescale the irt-parameters of test A -because we are equating test A with B- using the two constants as follows:</p>
<pre class="sourceCode r"><code class="sourceCode r">irtS[[<span class="dv">1</span>]]<span class="op">$</span>a&lt;-irtS[[<span class="dv">1</span>]]<span class="op">$</span>a<span class="op">/</span>Sl_a
irtS[[<span class="dv">1</span>]]<span class="op">$</span>b&lt;-Sl_a<span class="op">*</span>(irtS[[<span class="dv">1</span>]]<span class="op">$</span>b)<span class="op">+</span>Sl_b
irtS[[<span class="dv">1</span>]]</code></pre>
<pre><code>##            a         b c
## 1  0.4647126 2.8741830 0
## 2  0.5514052 1.2661333 0
## 3  0.5231797 2.0746222 0
## 4  0.5584616 1.9625249 0
## 5  1.2036157 0.9030572 0
## 6  1.1723661 0.6768787 0
## 7  1.0766010 0.4883967 0
## 8  0.9395057 1.5419123 0
## 9  0.7217662 1.6371454 0
## 10 0.6068481 2.5527715 0
## 11 1.6461512 0.9199214 0
## 12 1.6149015 1.0320187 0
## 13 1.3538157 1.2611732 0
## 14 1.4193392 1.4040228 0
## 15 1.1219634 1.7125382 0</code></pre>
<p>Now we have equivalent IRT-parameters so the latent scores can be fully compared. Section XX described two types of equating: observed and true. We will implement both below. For the true scale equating we simply say the names of the objects with the IRT-parameters, the method and we will use the following defaults for the scaling parameters <span class="math inline">\(A=1\)</span> and <span class="math inline">\(B=0\)</span>. We also specify the common items. We store the results on the <code>true-eqscale</code> object. For the observed equating we need to specify the <code>theta_points</code>, i.e. the standardised values of the latent poverty level. Then we apply the function changing the method and adding the theta points. We store the output on the <code>obs_eqscale</code> object.</p>
<pre class="sourceCode r"><code class="sourceCode r">theta_points=<span class="kw">c</span>(<span class="op">-</span><span class="dv">5</span>,<span class="op">-</span><span class="dv">4</span>,<span class="op">-</span><span class="dv">3</span>,<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>)

true_eqscale&lt;-<span class="kw">irt.eq</span>(<span class="dv">15</span>, irtS[[<span class="dv">1</span>]], irtS[[<span class="dv">2</span>]], <span class="dt">method=</span><span class="st">&quot;TS&quot;</span>, <span class="dt">A=</span><span class="dv">1</span>, <span class="dt">B=</span><span class="dv">0</span>, <span class="dt">common=</span>comitems)
obs_eqscale&lt;-<span class="kw">irt.eq</span>(<span class="dv">15</span>, irtS[[<span class="dv">1</span>]], irtS[[<span class="dv">2</span>]], theta_points, <span class="dt">method=</span><span class="st">&quot;OS&quot;</span>, <span class="dt">common=</span>comitems,
                                             <span class="dt">A=</span><span class="dv">1</span>, <span class="dt">B=</span><span class="dv">0</span>)</code></pre>
<p>We now do some manipulations to the <code>true_mean</code> object to extract the equated scores of form A in terms of B (<code>true_eqscale$tau_y</code>) and the latent values of poverty for each equated score (<code>true_eqscale$theta_equivalent</code>). We create a simple table to compare the equated score A in terms of B. We observed that the values of A in terms of B tend to be higher. Why is that? Remember that A had more severe indicators. That means that being deprived under test B was less severe. The number of deprivations in test A and B do not reflect the same severity levels, the latent severity under test A requires a higher observed deprivation score.</p>
<p>Sometimes is tricky to interpret these findings are there are double negatives. One way to think about this is by thinking in terms of an extreme situation. Imagine that test A is way more severe than test B, for example, test A uses indicators like having dirt floor, lacking electricity, unsafe source of water, walls made from cardboard to identify deprivation relative to B that uses indicators like floor without tiles, cant’ afford electricity, clean water connected to the property, lacking walls made from cement or bricks. For the same living standards, a score of 4 in test A denotes a more extreme situation than a score equal to 4 in test B. Thus, the same severity of A in terms of B should be way higher. In the current example we have something similar but less dramatic.</p>
<pre class="sourceCode r"><code class="sourceCode r">true_mean&lt;-<span class="kw">data.frame</span>(<span class="dt">Score.AintermsofB=</span>true_eqscale<span class="op">$</span>tau_y, <span class="dt">Latent=</span>true_eqscale<span class="op">$</span>theta_equivalent)
true_mean<span class="op">$</span>ScoreB&lt;-<span class="dv">0</span><span class="op">:</span><span class="dv">15</span>
true_mean</code></pre>
<pre><code>##    Score.AintermsofB     Latent ScoreB
## 1           0.000000         NA      0
## 2           1.188709 -0.4247446      1
## 3           2.421778  0.1052714      2
## 4           3.669205  0.4208060      3
## 5           4.881500  0.6582886      4
## 6           6.031033  0.8596392      5
## 7           7.106226  1.0445579      6
## 8           8.105683  1.2252625      7
## 9           9.034292  1.4114606      8
## 10          9.901703  1.6130816      9
## 11         10.722464  1.8430339     10
## 12         11.516009  2.1214140     11
## 13         12.305498  2.4841349     12
## 14         13.113282  3.0055632     13
## 15         13.958555  3.8932022     14
## 16         15.000000         NA     15</code></pre>
<p>Now we will do the same extraction process for the observed score. We extract the values of the A score in terms of B (<code>obs_eqscale$e_Y_x</code>). We find that we get similar results. The observed score of A in terms of B is higher than the score of index B.</p>
<pre class="sourceCode r"><code class="sourceCode r">obs_mean&lt;-<span class="kw">data.frame</span>(<span class="dt">Score.AintermsofB=</span>obs_eqscale<span class="op">$</span>e_Y_x, <span class="dt">obs_mean=</span><span class="kw">c</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">15</span>))
obs_mean</code></pre>
<pre><code>##    Score.AintermsofB obs_mean
## 1         0.03504469        0
## 2         1.21786830        1
## 3         2.42744874        2
## 4         3.65481175        3
## 5         4.77906519        4
## 6         5.87427729        5
## 7         6.98382632        6
## 8         8.04186994        7
## 9         9.02268088        8
## 10        9.96813153        9
## 11       10.87083780       10
## 12       11.69546817       11
## 13       12.46321205       12
## 14       13.30906666       13
## 15       14.19724649       14
## 16       15.12263638       15</code></pre>
<p>To see these findings from a different perspective, we will plot the results (See Figure <a href="scale-equating-and-linking.html#fig:eqfig1">6.2</a>. The first plot uses a 45 degree line to denote a situation where scores A and B are the same, i.e. a score of 3 measures the same underlying level of poverty. The pink line is the score A in terms of B. We see that the pink line is almost always below the 45-degree line. This means that the rescaled score A is always higher than B. For the same severity, someone assessed using index A has a higher observed deprivation score.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(true_mean,<span class="kw">aes</span>(Score.AintermsofB,ScoreB)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>(<span class="dt">size=</span><span class="dv">2</span>, <span class="dt">color=</span><span class="st">&quot;pink&quot;</span>) <span class="op">+</span><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Measure A (scaled in B-terms)&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">&quot;Measure B&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>() <span class="op">+</span><span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="dv">0</span>, <span class="dt">slope =</span> <span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>( <span class="dt">limits =</span> <span class="kw">c</span>(<span class="op">-</span>.<span class="dv">1</span>,<span class="dv">15</span>), <span class="dt">expand =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>), <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">15</span>, <span class="dv">1</span>) ) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>( <span class="dt">limits =</span> <span class="kw">c</span>(<span class="op">-</span>.<span class="dv">1</span>,<span class="dv">15</span>), <span class="dt">expand =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>), <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">15</span>, <span class="dv">1</span>)) </code></pre>
<div class="figure"><span id="fig:eqfig1"></span>
<img src="PM_Book_files/figure-html/eqfig1-1.png" alt="Comparison of the rescaled index A -in terms of B- with the index B." width="672" />
<p class="caption">
Figure 6.2: Comparison of the rescaled index A -in terms of B- with the index B.
</p>
</div>
</div>
<div id="real-data-example-2" class="section level2">
<h2><span class="header-section-number">6.4</span> Real-data example</h2>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="Chapter-5.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="identifying-the-poor-group.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "readable",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
